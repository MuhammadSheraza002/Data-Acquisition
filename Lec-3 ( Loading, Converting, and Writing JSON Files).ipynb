{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---   \n",
    " <img align=\"left\" width=\"75\" height=\"75\"  src=\"https://upload.wikimedia.org/wikipedia/en/c/c8/University_of_the_Punjab_logo.png\"> \n",
    "\n",
    "<h1 align=\"center\">Department of Data Science</h1>\n",
    "<h1 align=\"center\">Course: Data-Acquisition</h1>\n",
    "\n",
    "---  \n",
    "<h1 align=\"center\">Lecture 3 (Loading, Converting, and Writing JSON Files)</h1>\n",
    "\n",
    "----\n",
    "<img align=\"left\" width=\"400\" src=\"images/acq.PNG\"  >\n",
    "<img align=\"center\" width=\"400\" height=\"650\"  src=\"images/scrap.PNG\"  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Table of Contents\r\n",
    "\r\n",
    "## Loading, Converting, and Writing JSON Files\r\n",
    "\r\n",
    "- [Introduction: Douglas Crockfordâ€™s JSON Saga](#introduction-douglas-crockfords-json-saga)\r\n",
    "- [The Structure of a JSON File](#the-structure-of-a-json-file)\r\n",
    "- [Lists, Sets, and Dictionaries](#lists-sets-and-dictionaries)\r\n",
    "- [Nested Structures](#nested-structures)\r\n",
    "- [Metadata](#metadata)\r\n",
    "- [Missing Values and Different Data Types](#missing-values-and-different-data-types)\r\n",
    "\r\n",
    "## Loading and Reading JSON Data in Python\r\n",
    "\r\n",
    "- [Using the `requests.get()`, `json.loads()`, and `json.dumps()` Functions](#using-the-requestsget-jsonloads-and-jsondumps-functions)\r\n",
    "- [Searching Along the JSON Index Path](#searching-along-the-json-index-path)\r\n",
    "- [Looping Across Records to Extract Datapoints](#looping-across-records-to-extract-datapoints)\r\n",
    "- [Using `pd.read_json()` and `pd.json_normalize()` to Store JSON Data in a Data Frame](#using-pdreadjson-and-pdjsonnormalize-to-store-json-data-in-a-data-frame)\r\n",
    "\r\n",
    "## Situations with JSON Data\r\n",
    "\r\n",
    "- [Situation 1: No nesting, no metadata](#situation-1-no-nesting-no-metadata)\r\n",
    "- [Situation 2: Nesting, but no metadata](#situation-2-nesting-but-no-metadata)\r\n",
    "- [Situation 3: Metadata](#situation-3-metadata)\r\n",
    "\r\n",
    "## Saving JSON Files and Converting Data Frames to JSON\r\n",
    "\r\n",
    "- [Saving Existing JSON Files to Disk](#saving-existing-json-files-to-disk)\r\n",
    "- [Converting Tabular DataFrames to JSON](#converting-tabular-dataframes-to-json)\r\n",
    "abular-dataframes-to-json)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Introduction: Douglas Crockford's JSON Saga\r\n",
    "\r\n",
    "- **JSON Definition:** Stands for **JavaScript Object Notation**, widely used for data transfer over the Internet, especially in web-based systems like APIs.\r\n",
    "\r\n",
    "- **Attribution to Douglas Crockford:** Douglas Crockford, a JavaScript architect at Yahoo!, is credited with JSON's development. However, he emphasizes that he didn't invent it but rather discovered, named, and described its utility.\r\n",
    "\r\n",
    "- **Crockford's Perspective:** In his own words, \"I discovered JSON. I do not claim to have invented JSON because it already existed in nature.\"\r\n",
    "\r\n",
    "- **Origins of JSON:** Crockford delves into the early struggles and efforts to create a universal and lightweight language for data transfer in a [talk](insert_link_here).\r\n",
    "\r\n",
    "- **Talk Description:** Crockford's talk lasts around 50 minutes, where he narrates the origin story of JSON and the challenges faced in establishing it as a go-to data format. Despite its length, the talk is highly recommended for a comprehensive understanding of JSON's development.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"560\"\n",
       "            height=\"315\"\n",
       "            src=\"https://www.youtube.com/embed/-C-JoyNuQJs\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x165c2c68d90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src=\"https://www.youtube.com/embed/-C-JoyNuQJs\", width=\"560\", height=\"315\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Douglas Crockford's Insights on JSON Pronunciation and Objectives\r\n",
    "\r\n",
    "- **Pronunciation:** For clarification, Douglas Crockford pronounces \"JSON\" as \"Jay-Sin,\" akin to the first name. However, he humorously mentions that he \"strictly doesn't care\" about how others choose to pronounce it.\r\n",
    "\r\n",
    "- **Objective of JSON Development (2001):**\r\n",
    "  - **Universal Nature:** JSON was developed in 2001 with the primary goal of creating a language that works seamlessly on every browser. The objective is universality, ensuring data readability across different environments.\r\n",
    "\r\n",
    "  - **Lightweight Design:** JSON is deliberately designed to be as lightweight as possible. This means the code is compact and sacrifices features like comments, processing instructions, or attributes to minimize its size.\r\n",
    "\r\n",
    "  - **Faster Data Interchange:** The lightweight construction of JSON contributes to its speed, making it significantly faster than alternative data interchange languages like XML.\r\n",
    "\r\n",
    "  - **Universality and Minimalism:** JSON's minimalist approach helps achieve universality. A lightweight language integrates seamlessly into existing infrastructures without requiring additional software or extraneous code. Its minimalist data structure aligns with every programming language's concept of data.\r\n",
    "\r\n",
    "- **Crockford's Perspective:** In Crockford's own words, this design philosophy aims to create a data format that is universal, lightweight, and works effortlessly within diverse programming environments.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "> One of the key design goals behind JSON was minimalism. My idea was that the less we have to agree on in order to inter-operate, the more likely we're going to be able to inter-operate well. If the interfaces are really simple, we can easily connect, and if the interfaces are really complicated, the likelihood that something's going to go wrong goes way, way up. So I endeavored to make JSON as simple as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get to examples of using JSONs in Python, load the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import sys\n",
    "sys.tracebacklimit = 0 # turn off the long tracebacks on error messages\n",
    "#sys.tracebacklimit = None # use to turn tracebacks back on if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python `json` Package\n",
    "\n",
    "Python includes a powerful built-in package called `json` that facilitates working with JSON data..\n",
    "\n",
    "## Features\n",
    "\n",
    "- **Serialization:** Convert Python objects to JSON format.\n",
    "- **Deserialization:** Parse JSON data into Python objects.\n",
    "- **Compatibility:** Supports standard JSON data types.\n",
    "- **Readability:** Provides methods for pretty-printing JSON data.\n",
    "\n",
    "## Example Usage\n",
    "\n",
    "```python\n",
    "import json\n",
    "\n",
    "# Serialize Python object to JSON\n",
    "data = {\"name\": \"John\", \"age\": 25}\n",
    "json_string = json.dumps(data)\n",
    "\n",
    "# Deserialize JSON to Python object\n",
    "parsed_data = json.loads(json_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert from JSON to Python\n",
    "If you have a `JSON string`, you can parse it by using the `json.loads()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \"name\":\"John\", \"age\":30, \"city\":\"New York\"}\n",
      "<class 'str'>\n",
      "{'name': 'John', 'age': 30, 'city': 'New York'}\n",
      "<class 'dict'>\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# some JSON:\n",
    "x = '{ \"name\":\"John\", \"age\":30, \"city\":\"New York\"}'\n",
    "print(x)\n",
    "print(type(x))\n",
    "# parse x:\n",
    "y = json.loads(x)\n",
    "print(y)\n",
    "print(type(y))\n",
    "# the result is a Python dictionary:\n",
    "print(y[\"age\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert from Python to JSON\n",
    "If you have a Python object, you can convert it into a `json String` by using the `json.dumps()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{\"name\": \"John\", \"age\": 30, \"city\": \"New York\"}\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# a Python object (dict):\n",
    "x = {\n",
    "  \"name\": \"John\",\n",
    "  \"age\": 30,\n",
    "  \"city\": \"New York\"\n",
    "}\n",
    "print(type(x))\n",
    "\n",
    "# convert into JSON:\n",
    "y = json.dumps(x)\n",
    "\n",
    "# the result is a JSON string:\n",
    "print(y)\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You can convert Python objects of the following types, into JSON strings:**\n",
    "\n",
    "- dict\n",
    "- list\n",
    "- tuple\n",
    "- string\n",
    "- int\n",
    "- float\n",
    "- True\n",
    "- False\n",
    "- None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**\n",
    "- Convert Python objects into JSON strings, and print the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary:\n",
      "{\"name\": \"John\", \"age\": 30} <class 'str'>\n",
      "\n",
      "List:\n",
      "[\"apple\", \"bananas\"] <class 'str'>\n",
      "\n",
      "Tuple:\n",
      "[\"apple\", \"bananas\"] <class 'str'>\n",
      "\n",
      "String:\n",
      "\"hello\" <class 'str'>\n",
      "\n",
      "Integer:\n",
      "42 <class 'str'>\n",
      "\n",
      "Float:\n",
      "31.76 <class 'str'>\n",
      "\n",
      "Boolean (True):\n",
      "true <class 'str'>\n",
      "\n",
      "Boolean (False):\n",
      "false <class 'str'>\n",
      "\n",
      "None:\n",
      "null <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(\"Dictionary:\")\n",
    "json_dict = json.dumps({\"name\": \"John\", \"age\": 30})\n",
    "print(json_dict, type(json_dict))\n",
    "\n",
    "print(\"\\nList:\")\n",
    "json_list = json.dumps([\"apple\", \"bananas\"])\n",
    "print(json_list, type(json_list))\n",
    "\n",
    "print(\"\\nTuple:\")\n",
    "json_tuple = json.dumps((\"apple\", \"bananas\"))\n",
    "print(json_tuple, type(json_tuple))\n",
    "\n",
    "print(\"\\nString:\")\n",
    "json_string = json.dumps(\"hello\")\n",
    "print(json_string, type(json_string))\n",
    "\n",
    "print(\"\\nInteger:\")\n",
    "json_int = json.dumps(42)\n",
    "print(json_int, type(json_int))\n",
    "\n",
    "print(\"\\nFloat:\")\n",
    "json_float = json.dumps(31.76)\n",
    "print(json_float, type(json_float))\n",
    "\n",
    "print(\"\\nBoolean (True):\")\n",
    "json_true = json.dumps(True)\n",
    "print(json_true, type(json_true))\n",
    "\n",
    "print(\"\\nBoolean (False):\")\n",
    "json_false = json.dumps(False)\n",
    "print(json_false, type(json_false))\n",
    "\n",
    "print(\"\\nNone:\")\n",
    "json_none = json.dumps(None)\n",
    "print(json_none, type(json_none))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **When you convert from Python to JSON, Python objects are converted into the JSON (JavaScript) equivalent:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Python      | JSON         |\r\n",
    "|:------------|:-------------|\r\n",
    "| `dict`      | `Object`     |\r\n",
    "| `list`      | `Array`      |\r\n",
    "| `tuple`     | `Array`      |\r\n",
    "| `str`       | `String`     |\r\n",
    "| `int`       | `Number`     |\r\n",
    "| `float`     | `Number`     |\r\n",
    "| `True`      | `true`       |\r\n",
    "| `False`     | `false`      |\r\n",
    "| `None`      | `null`       |\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**\n",
    "- Convert JSON strings into Python Objects, and print the values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary: {'name': 'John', 'age': 30} <class 'dict'>\n",
      "List: ['apple', 'bananas'] <class 'list'>\n",
      "Tuple: ['apple', 'bananas'] <class 'list'>\n",
      "String: hello <class 'str'>\n",
      "Integer: 42 <class 'int'>\n",
      "Float: 31.76 <class 'float'>\n",
      "Boolean (True): True <class 'bool'>\n",
      "Boolean (False): False <class 'bool'>\n",
      "None: None <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "# JSON strings\n",
    "json_dict = '{\"name\": \"John\", \"age\": 30}'\n",
    "json_list = '[\"apple\", \"bananas\"]'\n",
    "json_tuple = '[\"apple\", \"bananas\"]'\n",
    "json_string = '\"hello\"'\n",
    "json_int = '42'\n",
    "json_float = '31.76'\n",
    "json_true = 'true'\n",
    "json_false = 'false'\n",
    "json_none = 'null'\n",
    "\n",
    "# Convert JSON strings to Python objects\n",
    "python_dict = json.loads(json_dict)\n",
    "python_list = json.loads(json_list)\n",
    "python_tuple = json.loads(json_tuple)\n",
    "python_string = json.loads(json_string)\n",
    "python_int = json.loads(json_int)\n",
    "python_float = json.loads(json_float)\n",
    "python_true = json.loads(json_true)\n",
    "python_false = json.loads(json_false)\n",
    "python_none = json.loads(json_none)\n",
    "\n",
    "# Print the values\n",
    "print(\"Dictionary:\", python_dict, type(python_dict))\n",
    "print(\"List:\", python_list, type(python_list))\n",
    "print(\"Tuple:\", python_tuple, type(python_tuple))\n",
    "print(\"String:\", python_string, type(python_string))\n",
    "print(\"Integer:\", python_int, type(python_int))\n",
    "print(\"Float:\", python_float, type(python_float))\n",
    "print(\"Boolean (True):\", python_true, type(python_true))\n",
    "print(\"Boolean (False):\", python_false, type(python_false))\n",
    "print(\"None:\", python_none, type(python_none))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **When you convert from JSON to Python,JSON (JavaScript)  are converted into the Python objects equivalent:**\n",
    "\n",
    "| JSON         | Python      |\n",
    "|:-------------:|:------------:|\n",
    "| `Object`     | `dict`      |\n",
    "| `Array`      | `list`      |\n",
    "| `Array`      | `tuple`     |\n",
    "| `String`     | `str`       |\n",
    "| `Number`     | `int`       |\n",
    "| `Number`     | `float`     |\n",
    "| `true`       | `True`      |\n",
    "| `false`      | `False`     |\n",
    "| `null`       | `None`      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**\n",
    "- Convert a Python object containing all the legal data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"name\": \"John\", \"age\": 30, \"married\": true, \"divorced\": false, \"children\": [\"Ann\", \"Billy\"], \"pets\": null, \"cars\": [{\"model\": \"BMW 230\", \"mpg\": 27.5}, {\"model\": \"Ford Edge\", \"mpg\": 24.1}]}\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "x = {\n",
    "  \"name\": \"John\",\n",
    "  \"age\": 30,\n",
    "  \"married\": True,\n",
    "  \"divorced\": False,\n",
    "  \"children\": (\"Ann\",\"Billy\"),\n",
    "  \"pets\": None,\n",
    "  \"cars\": [\n",
    "    {\"model\": \"BMW 230\", \"mpg\": 27.5},\n",
    "    {\"model\": \"Ford Edge\", \"mpg\": 24.1}\n",
    "  ]\n",
    "}\n",
    "\n",
    "print(json.dumps(x))\n",
    "print(type(json.dumps(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format the Result\n",
    "The example above prints a JSON string, but it is not very easy to read, with no `indentations` and line breaks.\n",
    "\n",
    "The `json.dumps()` method has parameters to make it easier to read the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'John',\n",
       " 'age': 30,\n",
       " 'married': True,\n",
       " 'divorced': False,\n",
       " 'children': ('Ann', 'Billy'),\n",
       " 'pets': None,\n",
       " 'cars': [{'model': 'BMW 230', 'mpg': 27.5},\n",
       "  {'model': 'Ford Edge', 'mpg': 24.1}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"name\": \"John\",\\n    \"age\": 30,\\n    \"married\": true,\\n    \"divorced\": false,\\n    \"children\": [\\n        \"Ann\",\\n        \"Billy\"\\n    ],\\n    \"pets\": null,\\n    \"cars\": [\\n        {\\n            \"model\": \"BMW 230\",\\n            \"mpg\": 27.5\\n        },\\n        {\\n            \"model\": \"Ford Edge\",\\n            \"mpg\": 24.1\\n        }\\n    ]\\n}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(x, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"John\",\n",
      "  \"age\": 30\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Python dictionary\n",
    "data = {\"name\": \"John\", \"age\": 30}\n",
    "\n",
    "# Convert to formatted JSON string\n",
    "formatted_json = json.dumps(data, indent=2)\n",
    "\n",
    "# Print the formatted JSON string\n",
    "print(f\"{formatted_json}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **You can also define the separators, default value is (\", \", \": \"), which means using a comma and a space to separate each object, and a colon and a space to separate keys from values:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "- **Use the separators parameter to change the default separator:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **`separators=(\". \", \" = \")`:** This parameter is optional and used in the `json.dumps()` function. It enables you to define custom separators for the resulting JSON string.\r\n",
    "  - The first element of the tuple (`\". \"`) specifies the separator between` item`s in a JSON object.\r\n",
    "  - The second element (`\" = \"`) determines the separator betwee`n ke`ys an`d valu`es in a JSON object.\r\n",
    "  - In this specific case, it would create a JSON string with dots and spaces between items and equal signs and spaces between keys and values.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"name\" = \"John\". \\n    \"age\" = 30. \\n    \"city\" = \"New York\"\\n}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(x, indent=4, separators=(\". \", \" = \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order the Result\n",
    "The `json.dumps()` method has parameters to `order` the keys in the result:\n",
    "\n",
    "**Example**\r",
    "- \n",
    "Use the sort_keys parameter to specify if the result should be sorted or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"age\": 30,\\n    \"cars\": [\\n        {\\n            \"model\": \"BMW 230\",\\n            \"mpg\": 27.5\\n        },\\n        {\\n            \"model\": \"Ford Edge\",\\n            \"mpg\": 24.1\\n        }\\n    ],\\n    \"children\": [\\n        \"Ann\",\\n        \"Billy\"\\n    ],\\n    \"divorced\": false,\\n    \"married\": true,\\n    \"name\": \"John\",\\n    \"pets\": null\\n}'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(x, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Structure of a JSON File\n",
    "The biggest difference between JSON (and other data interchange formats like XML, PHP, and YAML) and CSV is that JSON accomodates **tree-based** data structures, whereas CSV only handles **tabular** data. Many real-world applications require a tree-based structure for data. For example, here are the first two records from fake data from a business's customer records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"id\": 1,\n",
      "    \"name\": \"Leanne Graham\",\n",
      "    \"username\": \"Bret\",\n",
      "    \"email\": \"Sincere@april.biz\",\n",
      "    \"address\": {\n",
      "      \"street\": \"Kulas Light\",\n",
      "      \"suite\": \"Apt. 556\",\n",
      "      \"city\": \"Gwenborough\",\n",
      "      \"zipcode\": \"92998-3874\",\n",
      "      \"geo\": {\n",
      "        \"lat\": \"-37.3159\",\n",
      "        \"lng\": \"81.1496\"\n",
      "      }\n",
      "    },\n",
      "    \"phone\": \"1-770-736-8031 x56442\",\n",
      "    \"website\": \"hildegard.org\",\n",
      "    \"company\": {\n",
      "      \"name\": \"Romaguera-Crona\",\n",
      "      \"catchPhrase\": \"Multi-layered client-server neural-net\",\n",
      "      \"bs\": \"harness real-time e-markets\"\n",
      "    }\n",
      "  },\n",
      "  {\n",
      "    \"id\": 2,\n",
      "    \"name\": \"Ervin Howell\",\n",
      "    \"username\": \"Antonette\",\n",
      "    \"email\": \"Shanna@melissa.tv\",\n",
      "    \"address\": {\n",
      "      \"street\": \"Victor Plains\",\n",
      "      \"suite\": \"Suite 879\",\n",
      "      \"city\": \"Wisokyburgh\",\n",
      "      \"zipcode\": \"90566-7771\",\n",
      "      \"geo\": {\n",
      "        \"lat\": \"-43.9509\",\n",
      "        \"lng\": \"-34.4618\"\n",
      "      }\n",
      "    },\n",
      "    \"phone\": \"010-692-6593 x09125\",\n",
      "    \"website\": \"anastasia.net\",\n",
      "    \"company\": {\n",
      "      \"name\": \"Deckow-Crist\",\n",
      "      \"catchPhrase\": \"Proactive didactic contingency\",\n",
      "      \"bs\": \"synergize scalable supply-chains\"\n",
      "    }\n"
     ]
    }
   ],
   "source": [
    "users = requests.get(\"https://jsonplaceholder.typicode.com/users\")\n",
    "print(users.text[0:1110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>email</th>\n",
       "      <th>address</th>\n",
       "      <th>phone</th>\n",
       "      <th>website</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Leanne Graham</td>\n",
       "      <td>Bret</td>\n",
       "      <td>Sincere@april.biz</td>\n",
       "      <td>{'street': 'Kulas Light', 'suite': 'Apt. 556',...</td>\n",
       "      <td>1-770-736-8031 x56442</td>\n",
       "      <td>hildegard.org</td>\n",
       "      <td>{'name': 'Romaguera-Crona', 'catchPhrase': 'Mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ervin Howell</td>\n",
       "      <td>Antonette</td>\n",
       "      <td>Shanna@melissa.tv</td>\n",
       "      <td>{'street': 'Victor Plains', 'suite': 'Suite 87...</td>\n",
       "      <td>010-692-6593 x09125</td>\n",
       "      <td>anastasia.net</td>\n",
       "      <td>{'name': 'Deckow-Crist', 'catchPhrase': 'Proac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Clementine Bauch</td>\n",
       "      <td>Samantha</td>\n",
       "      <td>Nathan@yesenia.net</td>\n",
       "      <td>{'street': 'Douglas Extension', 'suite': 'Suit...</td>\n",
       "      <td>1-463-123-4447</td>\n",
       "      <td>ramiro.info</td>\n",
       "      <td>{'name': 'Romaguera-Jacobson', 'catchPhrase': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Patricia Lebsack</td>\n",
       "      <td>Karianne</td>\n",
       "      <td>Julianne.OConner@kory.org</td>\n",
       "      <td>{'street': 'Hoeger Mall', 'suite': 'Apt. 692',...</td>\n",
       "      <td>493-170-9623 x156</td>\n",
       "      <td>kale.biz</td>\n",
       "      <td>{'name': 'Robel-Corkery', 'catchPhrase': 'Mult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Chelsey Dietrich</td>\n",
       "      <td>Kamren</td>\n",
       "      <td>Lucio_Hettinger@annie.ca</td>\n",
       "      <td>{'street': 'Skiles Walks', 'suite': 'Suite 351...</td>\n",
       "      <td>(254)954-1289</td>\n",
       "      <td>demarco.info</td>\n",
       "      <td>{'name': 'Keebler LLC', 'catchPhrase': 'User-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Mrs. Dennis Schulist</td>\n",
       "      <td>Leopoldo_Corkery</td>\n",
       "      <td>Karley_Dach@jasper.info</td>\n",
       "      <td>{'street': 'Norberto Crossing', 'suite': 'Apt....</td>\n",
       "      <td>1-477-935-8478 x6430</td>\n",
       "      <td>ola.org</td>\n",
       "      <td>{'name': 'Considine-Lockman', 'catchPhrase': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Kurtis Weissnat</td>\n",
       "      <td>Elwyn.Skiles</td>\n",
       "      <td>Telly.Hoeger@billy.biz</td>\n",
       "      <td>{'street': 'Rex Trail', 'suite': 'Suite 280', ...</td>\n",
       "      <td>210.067.6132</td>\n",
       "      <td>elvis.io</td>\n",
       "      <td>{'name': 'Johns Group', 'catchPhrase': 'Config...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Nicholas Runolfsdottir V</td>\n",
       "      <td>Maxime_Nienow</td>\n",
       "      <td>Sherwood@rosamond.me</td>\n",
       "      <td>{'street': 'Ellsworth Summit', 'suite': 'Suite...</td>\n",
       "      <td>586.493.6943 x140</td>\n",
       "      <td>jacynthe.com</td>\n",
       "      <td>{'name': 'Abernathy Group', 'catchPhrase': 'Im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Glenna Reichert</td>\n",
       "      <td>Delphine</td>\n",
       "      <td>Chaim_McDermott@dana.io</td>\n",
       "      <td>{'street': 'Dayna Park', 'suite': 'Suite 449',...</td>\n",
       "      <td>(775)976-6794 x41206</td>\n",
       "      <td>conrad.com</td>\n",
       "      <td>{'name': 'Yost and Sons', 'catchPhrase': 'Swit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Clementina DuBuque</td>\n",
       "      <td>Moriah.Stanton</td>\n",
       "      <td>Rey.Padberg@karina.biz</td>\n",
       "      <td>{'street': 'Kattie Turnpike', 'suite': 'Suite ...</td>\n",
       "      <td>024-648-3804</td>\n",
       "      <td>ambrose.net</td>\n",
       "      <td>{'name': 'Hoeger LLC', 'catchPhrase': 'Central...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                      name          username                      email  \\\n",
       "0   1             Leanne Graham              Bret          Sincere@april.biz   \n",
       "1   2              Ervin Howell         Antonette          Shanna@melissa.tv   \n",
       "2   3          Clementine Bauch          Samantha         Nathan@yesenia.net   \n",
       "3   4          Patricia Lebsack          Karianne  Julianne.OConner@kory.org   \n",
       "4   5          Chelsey Dietrich            Kamren   Lucio_Hettinger@annie.ca   \n",
       "5   6      Mrs. Dennis Schulist  Leopoldo_Corkery    Karley_Dach@jasper.info   \n",
       "6   7           Kurtis Weissnat      Elwyn.Skiles     Telly.Hoeger@billy.biz   \n",
       "7   8  Nicholas Runolfsdottir V     Maxime_Nienow       Sherwood@rosamond.me   \n",
       "8   9           Glenna Reichert          Delphine    Chaim_McDermott@dana.io   \n",
       "9  10        Clementina DuBuque    Moriah.Stanton     Rey.Padberg@karina.biz   \n",
       "\n",
       "                                             address                  phone  \\\n",
       "0  {'street': 'Kulas Light', 'suite': 'Apt. 556',...  1-770-736-8031 x56442   \n",
       "1  {'street': 'Victor Plains', 'suite': 'Suite 87...    010-692-6593 x09125   \n",
       "2  {'street': 'Douglas Extension', 'suite': 'Suit...         1-463-123-4447   \n",
       "3  {'street': 'Hoeger Mall', 'suite': 'Apt. 692',...      493-170-9623 x156   \n",
       "4  {'street': 'Skiles Walks', 'suite': 'Suite 351...          (254)954-1289   \n",
       "5  {'street': 'Norberto Crossing', 'suite': 'Apt....   1-477-935-8478 x6430   \n",
       "6  {'street': 'Rex Trail', 'suite': 'Suite 280', ...           210.067.6132   \n",
       "7  {'street': 'Ellsworth Summit', 'suite': 'Suite...      586.493.6943 x140   \n",
       "8  {'street': 'Dayna Park', 'suite': 'Suite 449',...   (775)976-6794 x41206   \n",
       "9  {'street': 'Kattie Turnpike', 'suite': 'Suite ...           024-648-3804   \n",
       "\n",
       "         website                                            company  \n",
       "0  hildegard.org  {'name': 'Romaguera-Crona', 'catchPhrase': 'Mu...  \n",
       "1  anastasia.net  {'name': 'Deckow-Crist', 'catchPhrase': 'Proac...  \n",
       "2    ramiro.info  {'name': 'Romaguera-Jacobson', 'catchPhrase': ...  \n",
       "3       kale.biz  {'name': 'Robel-Corkery', 'catchPhrase': 'Mult...  \n",
       "4   demarco.info  {'name': 'Keebler LLC', 'catchPhrase': 'User-c...  \n",
       "5        ola.org  {'name': 'Considine-Lockman', 'catchPhrase': '...  \n",
       "6       elvis.io  {'name': 'Johns Group', 'catchPhrase': 'Config...  \n",
       "7   jacynthe.com  {'name': 'Abernathy Group', 'catchPhrase': 'Im...  \n",
       "8     conrad.com  {'name': 'Yost and Sons', 'catchPhrase': 'Swit...  \n",
       "9    ambrose.net  {'name': 'Hoeger LLC', 'catchPhrase': 'Central...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json('https://jsonplaceholder.typicode.com/users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "There are several elements of the JSON format that we need to discuss. \n",
    "\n",
    "### Lists, Sets, and Dictionaries\n",
    "First, notice the opening square brace `[`. This character tells Python to read all the following records as elements of a **list**. In a Python list, the order of the elements matters and elements can be repeated, but are not given names. The first element is denoted with index 0, the second element is denoted with index 1, and so on. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_list = [5,8,-9]\n",
    "my_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Within the JSON syntax, each individual element of the list is a **set**, denoted by curly braces `{` and `}`. A Python set differs from a Python list in that the order of the elements does not matter (it sorts the elements automatically), it doesn't allow repetition, and it allows the elements to be named. For example, in the following code, notice how the repeated 5s are removed and how the elements are sorted from smallest to largest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-9, 5, 8}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_set = {5,5,5,8,-9}\n",
    "my_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's only possible to use call individual elements of a set if those elements are given distinct names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_set = {'larry':5, 'curly':8, 'moe':-9}\n",
    "my_set['larry']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In Python, sets in which elements of a set have names are called **dictionaries**. The names are called **keys**, and the elements themselves are called **values**. So in this case, an element of the dictionary has a key of \"larry\" and a value of 5. Like sets, dictionaries enforce no repetition, but they apply this restriction to the keys only: multiple keys can have the same value, but every value must have a distinct key. In this example, I define the key \"larry\" twice, and only the last \"larry\" entered into the dictionary definition is saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'larry': 10, 'curly': 10, 'moe': -9}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_set = {'larry':15, 'larry':10, 'curly':10, 'moe':-9}\n",
    "my_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "That means that JSON notation is the same as a **list in which each element is a dictionary** in Python. Every dictionary represents one record in the data, and when we convert the data to a tabular dataframe, each record will occupy one row in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Nested Structures\n",
    "JSON can store data structures that are awkward or impossible for CSV. We can convert JSON formats to tabular formats to store the data in a data frame, but in doing so, we lose information about which features are nested within other fields. \n",
    "\n",
    "Let's return to the example of the customer records stored in JSON format.  In these data, some features are themselves dictionaries that contain additional features, resulting in a nested and tree-like shape to the data. The first record looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"id\": 1,\n",
      "    \"name\": \"Leanne Graham\",\n",
      "    \"username\": \"Bret\",\n",
      "    \"email\": \"Sincere@april.biz\",\n",
      "    \"address\": {\n",
      "      \"street\": \"Kulas Light\",\n",
      "      \"suite\": \"Apt. 556\",\n",
      "      \"city\": \"Gwenborough\",\n",
      "      \"zipcode\": \"92998-3874\",\n",
      "      \"geo\": {\n",
      "        \"lat\": \"-37.3159\",\n",
      "        \"lng\": \"81.1496\"\n",
      "      }\n",
      "    },\n",
      "    \"phone\": \"1-770-736-8031 x56442\",\n",
      "    \"website\": \"hildegard.org\",\n",
      "    \"company\": {\n",
      "      \"name\": \"Romaguera-Crona\",\n",
      "      \"catchPhrase\": \"Multi-layered client-server neural-net\",\n",
      "      \"bs\": \"harness real-time e-markets\"\n",
      "    }\n",
      "  },\n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(users.text[0:560])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "For this customer, we have the ID number, name, username, and email address. So far we can easily place these values in the same row of a table to store the same information. But the next key, `address`, is set equal to a dictionary, as indicated by the additional set of curly braces. Within the address field, we have data on the customer's street, suite, city, and ZIP code. We also have a field, `geo`, equal to yet another dictionary that contains the latitude and longitude coordinates of the address. The structure then returns to the first level of nesting, providing the phone number and website, before introducing another branch for company with three sub-fields: name, catch phrase, and business slogan. In all, the structure of this JSON data is best described with the following tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>website</th>\n",
       "      <th>address.street</th>\n",
       "      <th>address.suite</th>\n",
       "      <th>address.city</th>\n",
       "      <th>address.zipcode</th>\n",
       "      <th>address.geo.lat</th>\n",
       "      <th>address.geo.lng</th>\n",
       "      <th>company.name</th>\n",
       "      <th>company.catchPhrase</th>\n",
       "      <th>company.bs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Leanne Graham</td>\n",
       "      <td>Bret</td>\n",
       "      <td>Sincere@april.biz</td>\n",
       "      <td>1-770-736-8031 x56442</td>\n",
       "      <td>hildegard.org</td>\n",
       "      <td>Kulas Light</td>\n",
       "      <td>Apt. 556</td>\n",
       "      <td>Gwenborough</td>\n",
       "      <td>92998-3874</td>\n",
       "      <td>-37.3159</td>\n",
       "      <td>81.1496</td>\n",
       "      <td>Romaguera-Crona</td>\n",
       "      <td>Multi-layered client-server neural-net</td>\n",
       "      <td>harness real-time e-markets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id           name username              email                  phone  \\\n",
       "0   1  Leanne Graham     Bret  Sincere@april.biz  1-770-736-8031 x56442   \n",
       "\n",
       "         website address.street address.suite address.city address.zipcode  \\\n",
       "0  hildegard.org    Kulas Light      Apt. 556  Gwenborough      92998-3874   \n",
       "\n",
       "  address.geo.lat address.geo.lng     company.name  \\\n",
       "0        -37.3159         81.1496  Romaguera-Crona   \n",
       "\n",
       "                      company.catchPhrase                   company.bs  \n",
       "0  Multi-layered client-server neural-net  harness real-time e-markets  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"name\": \"Leanne Graham\",\n",
    "        \"username\": \"Bret\",\n",
    "        \"email\": \"Sincere@april.biz\",\n",
    "        \"address\": {\n",
    "            \"street\": \"Kulas Light\",\n",
    "            \"suite\": \"Apt. 556\",\n",
    "            \"city\": \"Gwenborough\",\n",
    "            \"zipcode\": \"92998-3874\",\n",
    "            \"geo\": {\n",
    "                \"lat\": \"-37.3159\",\n",
    "                \"lng\": \"81.1496\"\n",
    "            }\n",
    "        },\n",
    "        \"phone\": \"1-770-736-8031 x56442\",\n",
    "        \"website\": \"hildegard.org\",\n",
    "        \"company\": {\n",
    "            \"name\": \"Romaguera-Crona\",\n",
    "            \"catchPhrase\": \"Multi-layered client-server neural-net\",\n",
    "            \"bs\": \"harness real-time e-markets\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "df = pd.json_normalize(data)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"https://github.com/jkropko/DS-6001/raw/master/localimages/jsontree.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This tree can only be placed into a table, as we must do to work with a data frame, if we lose the information about nesting and instead treat the 15 distinct features as 15 columns in the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata\n",
    "In addition to nesting, JSON is an ideal format for placing metadata in the same file as the main data. Metadata is \"[data that provides information about other data](https://en.wikipedia.org/wiki/Metadata)\". Metadata might describe the date the data were last accessed, provide the stable URL for accessing the data, might credit authorship or describe copyright, and so on, prior to displaying information about each of the records in the data. In general, JSON formats with metadata can look like this:\n",
    "\n",
    "<img src=\"https://github.com/jkropko/DS-6001/raw/master/localimages/metadata.png\" width=300>\n",
    "\n",
    "In order to convert JSON data with a metadata format to a tabular data frame, you will have to specify the name of the branch that contains the records. As with nested structures, this procedure involves losing information. In this case, we will lose the metadata. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values and Different Data Types\n",
    "After unpacking the nested structure of a JSON data file and removing metadata, there can be differences from record to record in the information stored in the file. It's possible that some records do not have data on the same set of features that other records do. Even if the same feature is present across records, it is possible that its value has one data type in some records and another data type in other records. \n",
    "\n",
    "For example, consider public opinion data in which records are individuals answering questions on a survey and the features include an individual ID number, the individual's rating of the Republican Candidate, the individual's rating of the Democratic candidate, and the individual's birthyear and gender. One possible way a few records can look like in JSON format (and then converted to a data frame) is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "[{\"caseid\":1.0,\"ftrep\":\"Awful\",\"ftdem\":\"Pretty good\",\"birthyr\":1960},\n",
      "{\"caseid\":2.0,\"ftrep\":28.0,\"ftdem\":52.0,\"birthyr\":1987,\"gender\":2},\n",
      "{\"caseid\":3.0,\"ftrep\":100.0,\"ftdem\":1.0,\"gender\":1}]\n"
     ]
    }
   ],
   "source": [
    "case1 = '{\"caseid\":1.0,\"ftrep\":\"Awful\",\"ftdem\":\"Pretty good\",\"birthyr\":1960}'\n",
    "case2 = '{\"caseid\":2.0,\"ftrep\":28.0,\"ftdem\":52.0,\"birthyr\":1987,\"gender\":2}'\n",
    "case3 = '{\"caseid\":3.0,\"ftrep\":100.0,\"ftdem\":1.0,\"gender\":1}'\n",
    "case_json = '[' + case1 + ',\\n' + case2 + ',\\n' + case3 + ']'\n",
    "print(type(case_json))\n",
    "print(case_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseid</th>\n",
       "      <th>ftrep</th>\n",
       "      <th>ftdem</th>\n",
       "      <th>birthyr</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Awful</td>\n",
       "      <td>Pretty good</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   caseid  ftrep        ftdem  birthyr  gender\n",
       "0       1  Awful  Pretty good   1960.0     NaN\n",
       "1       2   28.0         52.0   1987.0     2.0\n",
       "2       3  100.0          1.0      NaN     1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(case_json)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a moment to look at the raw JSON formatted data. There are some differences between the three cases. The first case did not record the individual's gender and the third case did not record the individual's birthyear. Note that in the JSON format, these features are simply absent: we do not need to explicitly code these values as missing. When we convert the data to tabular format, the cells for the missing features are filled with `NaN` missing values automatically.\n",
    "\n",
    "Additionally, the first case records the feeling thermometer scores for the Republican and Democrat with strings: this person feels \"Awful\" towards the Republican and \"Pretty good\" towards the Democrat. For the second and third cases these ratings are coded numerically. The JSON format naturally allows the same feature to be populated by data of a different type across records. Tabular data, however, has stricter requirements for data uniformity within a column: specifically all of the data must have the same type in a column. The data frame handles that by coding all of these values with the ambiguous `object` type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "caseid       int64\n",
       "ftrep       object\n",
       "ftdem       object\n",
       "birthyr    float64\n",
       "gender     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_json(case_json).dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In short, while it is straightforward to convert JSON data to tabular format, we can potentially lose a great deal of information in this conversion: nesting, metadata, and varying data type. In addition, tabular data inefficiently require that cells for missing values be filled with a symbol to denote missingness, to preserve the rectangular shape of the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Reading JSON Data in Python\n",
    "JSON, like CSV and ASCII, is a **text-based** system for data storage. When first loading JSON data into Python, the data will be read as a giant block of text. First we need to get Python to understand that the text is actually organized JSON data using the `json` library. Once we can work with the data as JSON, we can search through the JSON data's index path to extract particular datapoints. We can even construct loops to pull out lists of values from across the records.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the `requests.get()`, `json.loads()` and `json.dumps()` Functions \n",
    "There is an important function from the `requests` library and two important functions in the `json` library for us to know when working with JSON data:\n",
    "\n",
    "* `requests.get()` downloads data from a URL and stores it in Python's memory as a giant block of text. It also can include additional parameters to send to the website to provide information on credentials or on specifying the subset of data to collect. \n",
    "\n",
    "* `json.loads()` converts text into an object that Python recognizes as JSON-formatted data.\n",
    "\n",
    "* `json.dumps()` converts JSON data into a block of text.\n",
    "\n",
    "Consider again the JSON data on fake consumer records. The data are stored on a website called [JSON Placeholder](https://jsonplaceholder.typicode.com/), which has several excellent example JSON datasets and has resources for guiding people who are writing their own APIs. The customer data exists here: https://jsonplaceholder.typicode.com/users. Take a moment and click on this link to see how the data appear in your web browser.\n",
    "\n",
    "To download the data, use `requests.get()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "users = requests.get(\"https://jsonplaceholder.typicode.com/users\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the text of this download, use the `.text` attribute. If I want to display only the first record, I have to specify the first and last character numbers of this record, which turns out to be (after a lot of guess-and-checking) the first 560 characters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"id\": 1,\n",
      "    \"name\": \"Leanne Graham\",\n",
      "    \"username\": \"Bret\",\n",
      "    \"email\": \"Sincere@april.biz\",\n",
      "    \"address\": {\n",
      "      \"street\": \"Kulas Light\",\n",
      "      \"suite\": \"Apt. 556\",\n",
      "      \"city\": \"Gwenborough\",\n",
      "      \"zipcode\": \"92998-3874\",\n",
      "      \"geo\": {\n",
      "        \"lat\": \"-37.3159\",\n",
      "        \"lng\": \"81.1496\"\n",
      "      }\n",
      "    },\n",
      "    \"phone\": \"1-770-736-8031 x56442\",\n",
      "    \"website\": \"hildegard.org\",\n",
      "    \"company\": {\n",
      "      \"name\": \"Romaguera-Crona\",\n",
      "      \"catchPhrase\": \"Multi-layered client-server neural-net\",\n",
      "      \"bs\": \"harness real-time e-markets\"\n",
      "    }\n",
      "  },\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(users.text[0:560])\n",
    "len(users.text[0:560])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presently, although the text above looks like it is formatted like a JSON file, Python only understands it as text (with type `str`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(users.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get Python to read this text as JSON data, make sure the `json` library is imported (which we did at the top of this notebook), and use the `json.loads()` function. Now, to display the first record, I only have to pass the index 0, representing the first item in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'name': 'Leanne Graham',\n",
       " 'username': 'Bret',\n",
       " 'email': 'Sincere@april.biz',\n",
       " 'address': {'street': 'Kulas Light',\n",
       "  'suite': 'Apt. 556',\n",
       "  'city': 'Gwenborough',\n",
       "  'zipcode': '92998-3874',\n",
       "  'geo': {'lat': '-37.3159', 'lng': '81.1496'}},\n",
       " 'phone': '1-770-736-8031 x56442',\n",
       " 'website': 'hildegard.org',\n",
       " 'company': {'name': 'Romaguera-Crona',\n",
       "  'catchPhrase': 'Multi-layered client-server neural-net',\n",
       "  'bs': 'harness real-time e-markets'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_json = json.loads(users.text)\n",
    "users_json[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of text, Python now recognizes `users_json` as a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(users_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>email</th>\n",
       "      <th>address</th>\n",
       "      <th>phone</th>\n",
       "      <th>website</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Glenna Reichert</td>\n",
       "      <td>Delphine</td>\n",
       "      <td>Chaim_McDermott@dana.io</td>\n",
       "      <td>{'street': 'Dayna Park', 'suite': 'Suite 449',...</td>\n",
       "      <td>(775)976-6794 x41206</td>\n",
       "      <td>conrad.com</td>\n",
       "      <td>{'name': 'Yost and Sons', 'catchPhrase': 'Swit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Leanne Graham</td>\n",
       "      <td>Bret</td>\n",
       "      <td>Sincere@april.biz</td>\n",
       "      <td>{'street': 'Kulas Light', 'suite': 'Apt. 556',...</td>\n",
       "      <td>1-770-736-8031 x56442</td>\n",
       "      <td>hildegard.org</td>\n",
       "      <td>{'name': 'Romaguera-Crona', 'catchPhrase': 'Mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Mrs. Dennis Schulist</td>\n",
       "      <td>Leopoldo_Corkery</td>\n",
       "      <td>Karley_Dach@jasper.info</td>\n",
       "      <td>{'street': 'Norberto Crossing', 'suite': 'Apt....</td>\n",
       "      <td>1-477-935-8478 x6430</td>\n",
       "      <td>ola.org</td>\n",
       "      <td>{'name': 'Considine-Lockman', 'catchPhrase': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Patricia Lebsack</td>\n",
       "      <td>Karianne</td>\n",
       "      <td>Julianne.OConner@kory.org</td>\n",
       "      <td>{'street': 'Hoeger Mall', 'suite': 'Apt. 692',...</td>\n",
       "      <td>493-170-9623 x156</td>\n",
       "      <td>kale.biz</td>\n",
       "      <td>{'name': 'Robel-Corkery', 'catchPhrase': 'Mult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Kurtis Weissnat</td>\n",
       "      <td>Elwyn.Skiles</td>\n",
       "      <td>Telly.Hoeger@billy.biz</td>\n",
       "      <td>{'street': 'Rex Trail', 'suite': 'Suite 280', ...</td>\n",
       "      <td>210.067.6132</td>\n",
       "      <td>elvis.io</td>\n",
       "      <td>{'name': 'Johns Group', 'catchPhrase': 'Config...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                  name          username                      email  \\\n",
       "8   9       Glenna Reichert          Delphine    Chaim_McDermott@dana.io   \n",
       "0   1         Leanne Graham              Bret          Sincere@april.biz   \n",
       "5   6  Mrs. Dennis Schulist  Leopoldo_Corkery    Karley_Dach@jasper.info   \n",
       "3   4      Patricia Lebsack          Karianne  Julianne.OConner@kory.org   \n",
       "6   7       Kurtis Weissnat      Elwyn.Skiles     Telly.Hoeger@billy.biz   \n",
       "\n",
       "                                             address                  phone  \\\n",
       "8  {'street': 'Dayna Park', 'suite': 'Suite 449',...   (775)976-6794 x41206   \n",
       "0  {'street': 'Kulas Light', 'suite': 'Apt. 556',...  1-770-736-8031 x56442   \n",
       "5  {'street': 'Norberto Crossing', 'suite': 'Apt....   1-477-935-8478 x6430   \n",
       "3  {'street': 'Hoeger Mall', 'suite': 'Apt. 692',...      493-170-9623 x156   \n",
       "6  {'street': 'Rex Trail', 'suite': 'Suite 280', ...           210.067.6132   \n",
       "\n",
       "         website                                            company  \n",
       "8     conrad.com  {'name': 'Yost and Sons', 'catchPhrase': 'Swit...  \n",
       "0  hildegard.org  {'name': 'Romaguera-Crona', 'catchPhrase': 'Mu...  \n",
       "5        ola.org  {'name': 'Considine-Lockman', 'catchPhrase': '...  \n",
       "3       kale.biz  {'name': 'Robel-Corkery', 'catchPhrase': 'Mult...  \n",
       "6       elvis.io  {'name': 'Johns Group', 'catchPhrase': 'Config...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(users_json).sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching Along the JSON Index Path\n",
    "After using `json.loads()`, Python understands the JSON data to be a list-of-lists. We can now use indices to extract particular datapoints. The records are numbers, starting with 0, and keys within particular records can be called by name.\n",
    "\n",
    "For example, to extract the email address of the fifth customer (element 4), in the data, I type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sincere@april.biz'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_json[0]['email']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we call fields that contain several nested features, Python returns a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'street': 'Kulas Light',\n",
       " 'suite': 'Apt. 556',\n",
       " 'city': 'Gwenborough',\n",
       " 'zipcode': '92998-3874',\n",
       " 'geo': {'lat': '-37.3159', 'lng': '81.1496'}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_json[0]['address']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract elements that are several levels of nesting down the JSON tree, specify the keys in order that lead to the desired element. For example, to extract the latitudinal coordinate, we navigate to the `address`, `geo`, and `lat` keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-37.3159'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_json[0]['address']['geo']['lat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it may be necessary at times to covert the JSON back to text, maybe to assist in transfering the data to another platform (although I recommend using the `.to_json()` method, discussed below, for this purpose). To convert JSON back to text, use the `json.dumps()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"id\": 1, \"name\": \"Leanne Graham\", \"username\": \"Bret\", \"email\": \"Sincere@april.biz\", \"address\": {\"street\": \"Kulas Light\", \"suite\": \"Apt. 556\", \"city\": \"Gwenborough\", \"zipcode\": \"92998-3874\", \"geo\": {\"lat\": \"-37.3159\", \"lng\": \"81.1496\"}}, \"phone\": \"1-770-736-8031 x56442\", \"website\": \"hildegard.org\", \"company\": {\"name\": \"Romaguera-Crona\", \"catchPhrase\": \"Multi-layered client-server neural-net\", \"bs\": \"harness real-time e-markets\"}}, {\"id\": 2, \"name\": \"Ervin Howell\", \"username\": \"Antonette\", \"email\": \"Shanna@melissa.tv\", \"address\": {\"street\": \"Victor Plains\", \"suite\": \"Suite 879\", \"city\": \"Wisokyburgh\", \"zipcode\": \"90566-7771\", \"geo\": {\"lat\": \"-43.9509\", \"lng\": \"-34.4618\"}}, \"phone\": \"010-692-6593 x09125\", \"website\": \"anastasia.net\", \"company\": {\"name\": \"Deckow-Crist\", \"catchPhrase\": \"Proactive didactic contingency\", \"bs\": \"synergize scalable supply-chains\"}}, {\"id\": 3, \"name\": \"Clementine Bauch\", \"username\": \"Samantha\", \"email\": \"Nathan@yesenia.net\", \"address\": {\"street\": \"Douglas Extension\", \"suite\": \"Suite 847\", \"city\": \"McKenziehaven\", \"zipcode\": \"59590-4157\", \"geo\": {\"lat\": \"-68.6102\", \"lng\": \"-47.0653\"}}, \"phone\": \"1-463-123-4447\", \"website\": \"ramiro.info\", \"company\": {\"name\": \"Romaguera-Jacobson\", \"catchPhrase\": \"Face to face bifurcated interface\", \"bs\": \"e-enable strategic applications\"}}, {\"id\": 4, \"name\": \"Patricia Lebsack\", \"username\": \"Karianne\", \"email\": \"Julianne.OConner@kory.org\", \"address\": {\"street\": \"Hoeger Mall\", \"suite\": \"Apt. 692\", \"city\": \"South Elvis\", \"zipcode\": \"53919-4257\", \"geo\": {\"lat\": \"29.4572\", \"lng\": \"-164.2990\"}}, \"phone\": \"493-170-9623 x156\", \"website\": \"kale.biz\", \"company\": {\"name\": \"Robel-Corkery\", \"catchPhrase\": \"Multi-tiered zero tolerance productivity\", \"bs\": \"transition cutting-edge web services\"}}, {\"id\": 5, \"name\": \"Chelsey Dietrich\", \"username\": \"Kamren\", \"email\": \"Lucio_Hettinger@annie.ca\", \"address\": {\"street\": \"Skiles Walks\", \"suite\": \"Suite 351\", \"city\": \"Roscoeview\", \"zipcode\": \"33263\", \"geo\": {\"lat\": \"-31.8129\", \"lng\": \"62.5342\"}}, \"phone\": \"(254)954-1289\", \"website\": \"demarco.info\", \"company\": {\"name\": \"Keebler LLC\", \"catchPhrase\": \"User-centric fault-tolerant solution\", \"bs\": \"revolutionize end-to-end systems\"}}, {\"id\": 6, \"name\": \"Mrs. Dennis Schulist\", \"username\": \"Leopoldo_Corkery\", \"email\": \"Karley_Dach@jasper.info\", \"address\": {\"street\": \"Norberto Crossing\", \"suite\": \"Apt. 950\", \"city\": \"South Christy\", \"zipcode\": \"23505-1337\", \"geo\": {\"lat\": \"-71.4197\", \"lng\": \"71.7478\"}}, \"phone\": \"1-477-935-8478 x6430\", \"website\": \"ola.org\", \"company\": {\"name\": \"Considine-Lockman\", \"catchPhrase\": \"Synchronised bottom-line interface\", \"bs\": \"e-enable innovative applications\"}}, {\"id\": 7, \"name\": \"Kurtis Weissnat\", \"username\": \"Elwyn.Skiles\", \"email\": \"Telly.Hoeger@billy.biz\", \"address\": {\"street\": \"Rex Trail\", \"suite\": \"Suite 280\", \"city\": \"Howemouth\", \"zipcode\": \"58804-1099\", \"geo\": {\"lat\": \"24.8918\", \"lng\": \"21.8984\"}}, \"phone\": \"210.067.6132\", \"website\": \"elvis.io\", \"company\": {\"name\": \"Johns Group\", \"catchPhrase\": \"Configurable multimedia task-force\", \"bs\": \"generate enterprise e-tailers\"}}, {\"id\": 8, \"name\": \"Nicholas Runolfsdottir V\", \"username\": \"Maxime_Nienow\", \"email\": \"Sherwood@rosamond.me\", \"address\": {\"street\": \"Ellsworth Summit\", \"suite\": \"Suite 729\", \"city\": \"Aliyaview\", \"zipcode\": \"45169\", \"geo\": {\"lat\": \"-14.3990\", \"lng\": \"-120.7677\"}}, \"phone\": \"586.493.6943 x140\", \"website\": \"jacynthe.com\", \"company\": {\"name\": \"Abernathy Group\", \"catchPhrase\": \"Implemented secondary concept\", \"bs\": \"e-enable extensible e-tailers\"}}, {\"id\": 9, \"name\": \"Glenna Reichert\", \"username\": \"Delphine\", \"email\": \"Chaim_McDermott@dana.io\", \"address\": {\"street\": \"Dayna Park\", \"suite\": \"Suite 449\", \"city\": \"Bartholomebury\", \"zipcode\": \"76495-3109\", \"geo\": {\"lat\": \"24.6463\", \"lng\": \"-168.8889\"}}, \"phone\": \"(775)976-6794 x41206\", \"website\": \"conrad.com\", \"company\": {\"name\": \"Yost and Sons\", \"catchPhrase\": \"Switchable contextually-based project\", \"bs\": \"aggregate real-time technologies\"}}, {\"id\": 10, \"name\": \"Clementina DuBuque\", \"username\": \"Moriah.Stanton\", \"email\": \"Rey.Padberg@karina.biz\", \"address\": {\"street\": \"Kattie Turnpike\", \"suite\": \"Suite 198\", \"city\": \"Lebsackbury\", \"zipcode\": \"31428-2261\", \"geo\": {\"lat\": \"-38.2386\", \"lng\": \"57.2232\"}}, \"phone\": \"024-648-3804\", \"website\": \"ambrose.net\", \"company\": {\"name\": \"Hoeger LLC\", \"catchPhrase\": \"Centralized empowering task-force\", \"bs\": \"target end-to-end models\"}}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_text = json.dumps(users_json)\n",
    "print(users_text)\n",
    "type(users_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping Across Records to Extract Datapoints\n",
    "While JSON is a well-organized and flexible data format that preserves a lot of the meaningful context of the data, most analytical tools and statistical models can only operate on tabular data. So a major challenge with JSON data is converting the data to a tabular format to be saved in a data frame. One method is to construct a loop across records to extract desired elements. \n",
    "\n",
    "Before we discuss this method, I do not recommend using this approach in general. Loops are usually slow, and it is much faster to perform these kinds of operations by **vectorizing** code. [Vectorizing](https://stackoverflow.com/questions/1422149/what-is-vectorization#1422181) refers to the ability of a programming language to operate on an entire vector of data and work on several elements simultaneously, rather than on each element one at a time. Vectorization is the specialty of the `numpy` library, and most functions in `pandas` are vectorized as well. I suggest using `pd.read_json()` and `pd.json_normalize()` to convert JSON data to a data frame as they will be several orders of magnitude faster for converting the entire JSON to a data frame. Looping make sense only when we need to extract a small number of features from JSON data with a large feature set, because with the loop we directly call the features we want and we can avoid having to work with features we don't need.\n",
    "\n",
    "To start the loop, choose an index to represent one record. To display all of the email addresses, type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sincere@april.biz\n",
      "Shanna@melissa.tv\n",
      "Nathan@yesenia.net\n",
      "Julianne.OConner@kory.org\n",
      "Lucio_Hettinger@annie.ca\n",
      "Karley_Dach@jasper.info\n",
      "Telly.Hoeger@billy.biz\n",
      "Sherwood@rosamond.me\n",
      "Chaim_McDermott@dana.io\n",
      "Rey.Padberg@karina.biz\n"
     ]
    }
   ],
   "source": [
    "for u in users_json:\n",
    "    print(u['email'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, to place all of the email addresses in a list, you can loop inside of a list like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sincere@april.biz',\n",
       " 'Shanna@melissa.tv',\n",
       " 'Nathan@yesenia.net',\n",
       " 'Julianne.OConner@kory.org',\n",
       " 'Lucio_Hettinger@annie.ca',\n",
       " 'Karley_Dach@jasper.info',\n",
       " 'Telly.Hoeger@billy.biz',\n",
       " 'Sherwood@rosamond.me',\n",
       " 'Chaim_McDermott@dana.io',\n",
       " 'Rey.Padberg@karina.biz']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = [u['email'] for u in users_json]\n",
    "emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trick is extracting the data and saving it in a data frame at the same time. We can do this by using the `pd.DataFrame()` function, and using list loops inside this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leanne Graham</td>\n",
       "      <td>Sincere@april.biz</td>\n",
       "      <td>Romaguera-Crona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ervin Howell</td>\n",
       "      <td>Shanna@melissa.tv</td>\n",
       "      <td>Deckow-Crist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clementine Bauch</td>\n",
       "      <td>Nathan@yesenia.net</td>\n",
       "      <td>Romaguera-Jacobson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Patricia Lebsack</td>\n",
       "      <td>Julianne.OConner@kory.org</td>\n",
       "      <td>Robel-Corkery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chelsey Dietrich</td>\n",
       "      <td>Lucio_Hettinger@annie.ca</td>\n",
       "      <td>Keebler LLC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mrs. Dennis Schulist</td>\n",
       "      <td>Karley_Dach@jasper.info</td>\n",
       "      <td>Considine-Lockman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kurtis Weissnat</td>\n",
       "      <td>Telly.Hoeger@billy.biz</td>\n",
       "      <td>Johns Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nicholas Runolfsdottir V</td>\n",
       "      <td>Sherwood@rosamond.me</td>\n",
       "      <td>Abernathy Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Glenna Reichert</td>\n",
       "      <td>Chaim_McDermott@dana.io</td>\n",
       "      <td>Yost and Sons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Clementina DuBuque</td>\n",
       "      <td>Rey.Padberg@karina.biz</td>\n",
       "      <td>Hoeger LLC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       name                      email        company_name\n",
       "0             Leanne Graham          Sincere@april.biz     Romaguera-Crona\n",
       "1              Ervin Howell          Shanna@melissa.tv        Deckow-Crist\n",
       "2          Clementine Bauch         Nathan@yesenia.net  Romaguera-Jacobson\n",
       "3          Patricia Lebsack  Julianne.OConner@kory.org       Robel-Corkery\n",
       "4          Chelsey Dietrich   Lucio_Hettinger@annie.ca         Keebler LLC\n",
       "5      Mrs. Dennis Schulist    Karley_Dach@jasper.info   Considine-Lockman\n",
       "6           Kurtis Weissnat     Telly.Hoeger@billy.biz         Johns Group\n",
       "7  Nicholas Runolfsdottir V       Sherwood@rosamond.me     Abernathy Group\n",
       "8           Glenna Reichert    Chaim_McDermott@dana.io       Yost and Sons\n",
       "9        Clementina DuBuque     Rey.Padberg@karina.biz          Hoeger LLC"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df = pd.DataFrame(\n",
    "    [u['name'], u['email'], u['company']['name']] for u in users_json\n",
    ")\n",
    "users_df.columns = ['name', 'email', 'company_name']\n",
    "users_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please, note, there are many many ways to construct a loop to extract JSON elements into a dataframe. If you look on Stack Overflow, for example, you will see many different approaches, and it can be confusing. Find an approach that you understand and feel comfortable using, and go with that. There's not much difference between one loop and the next, as the real improvement comes from vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using `pd.read_json()` and `pd.json_normalize()` to Store JSON Data in a Data Frame\n",
    "If there aren't too many features in the data, or if you want to keep all of the features in the data anyway, then the fastest and best way to convert JSON data to a tabular data frame depends on **whether or not the JSON data has metadata or a nested structure**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Situation 1: No nesting, no metadata\n",
    "\n",
    "If the JSON has no nesting - that is, if every key is associated with a single datapoint, and no key is associated with a dictionary that contains additional features - and also does not include metadata, then use the following steps:\n",
    "\n",
    "1. Use `requests.get()` to download the raw JSON data (unless you have another way of acquiring the raw data)\n",
    "\n",
    "2. Use `pd.read_json()` on the `.text` attribute of the output of `requests.get()`\n",
    "\n",
    "The result will be a dataframe in which the columns have the same names as the keys in the JSON file. For example, JSON Placeholder has an example JSON dataset that contains [random Latin posts to a blog](https://jsonplaceholder.typicode.com/posts). This JSON contains no metadata and no nesting. The best way to acquire this dataset and convert it to a dataframe is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n  {\\n    \"userId\": 1,\\n    \"id\": 1,\\n    \"title\": \"sunt aut facere repellat provident occaecati excepturi optio reprehenderit\",\\n    \"body\": \"quia et suscipit\\\\nsuscipit recusandae consequuntur expedita et cum\\\\nreprehenderit molestiae ut ut quas totam\\\\nnostrum rerum est autem sunt rem eveniet architecto\"\\n  },\\n  {\\n    \"userId\": 1,\\n    \"id\": 2,\\n    \"title\": \"qui est esse\",\\n    \"body\": \"est rerum tempore vitae\\\\nsequi sint nihil reprehenderit dolor beatae ea dolores neque\\\\nfugiat blanditiis voluptate porro vel nihil molestiae ut reiciendis\\\\nqui aperiam non debitis possimus qui neque nisi nulla\"\\n  },\\n  {\\n    \"userId\": 1,\\n    \"id\": 3,\\n    \"title\": \"ea molestias quasi exercitationem repellat qui ipsa sit aut\",\\n    \"body\": \"et iusto sed quo iure\\\\nvoluptatem occaecati omnis eligendi aut ad\\\\nvoluptatem doloribus vel accusantium quis pariatur\\\\nmolestiae porro eius odio et labore et velit aut\"\\n  },\\n  {\\n    \"userId\": 1,\\n    \"id\": 4,\\n    \"title\": \"eum et est occaecati\",\\n    \"body\": \"ullam et saepe reiciendis voluptatem adipisci\\\\nsit amet autem assumenda provident rerum culpa\\\\nquis hic commodi nesciunt rem tenetur doloremque ipsam iure\\\\nquis sunt voluptatem rerum illo velit\"\\n  },\\n  {\\n    \"userId\": 1,\\n    \"id\": 5,\\n    \"title\": \"nesciunt quas odio\",\\n    \"body\": \"repudiandae veniam quaerat sunt sed\\\\nalias aut fugiat sit autem sed est\\\\nvoluptatem omnis possimus esse voluptatibus quis\\\\nest aut tenetur dolor neque\"\\n  },\\n  {\\n    \"userId\": 1,\\n    \"id\": 6,\\n    \"title\": \"dolorem eum magni eos aperiam quia\",\\n    \"body\": \"ut aspernatur corporis harum nihil quis provident sequi\\\\nmollitia nobis aliquid molestiae\\\\nperspiciatis et ea nemo ab reprehenderit accusantium quas\\\\nvoluptate dolores velit et doloremque molestiae\"\\n  },\\n  {\\n    \"userId\": 1,\\n    \"id\": 7,\\n    \"title\": \"magnam facilis autem\",\\n    \"body\": \"dolore placeat quibusdam ea quo vitae\\\\nmagni quis enim qui quis quo nemo aut saepe\\\\nquidem repellat excepturi ut quia\\\\nsunt ut sequi eos ea sed quas\"\\n  },\\n  {\\n    \"userId\": 1,\\n    \"id\": 8,\\n    \"title\": \"dolorem dolore est ipsam\",\\n    \"body\": \"dignissimos aperiam dolorem qui eum\\\\nfacilis quibusdam animi sint suscipit qui sint possimus cum\\\\nquaerat magni maiores excepturi\\\\nipsam ut commodi dolor voluptatum modi aut vitae\"\\n  },\\n  {\\n    \"userId\": 1,\\n    \"id\": 9,\\n    \"title\": \"nesciunt iure omnis dolorem tempora et accusantium\",\\n    \"body\": \"consectetur animi nesciunt iure dolore\\\\nenim quia ad\\\\nveniam autem ut quam aut nobis\\\\net est aut quod aut provident voluptas autem voluptas\"\\n  },\\n  {\\n    \"userId\": 1,\\n    \"id\": 10,\\n    \"title\": \"optio molestias id quia eum\",\\n    \"body\": \"quo et expedita modi cum officia vel magni\\\\ndoloribus qui repudiandae\\\\nvero nisi sit\\\\nquos veniam quod sed accusamus veritatis error\"\\n  },\\n  {\\n    \"userId\": 2,\\n    \"id\": 11,\\n    \"title\": \"et ea vero quia laudantium autem\",\\n    \"body\": \"delectus reiciendis molestiae occaecati non minima eveniet qui voluptatibus\\\\naccusamus in eum beatae sit\\\\nvel qui neque voluptates ut commodi qui incidunt\\\\nut animi commodi\"\\n  },\\n  {\\n    \"userId\": 2,\\n    \"id\": 12,\\n    \"title\": \"in quibusdam tempore odit est dolorem\",\\n    \"body\": \"itaque id aut magnam\\\\npraesentium quia et ea odit et ea voluptas et\\\\nsapiente quia nihil amet occaecati quia id voluptatem\\\\nincidunt ea est distinctio odio\"\\n  },\\n  {\\n    \"userId\": 2,\\n    \"id\": 13,\\n    \"title\": \"dolorum ut in voluptas mollitia et saepe quo animi\",\\n    \"body\": \"aut dicta possimus sint mollitia voluptas commodi quo doloremque\\\\niste corrupti reiciendis voluptatem eius rerum\\\\nsit cumque quod eligendi laborum minima\\\\nperferendis recusandae assumenda consectetur porro architecto ipsum ipsam\"\\n  },\\n  {\\n    \"userId\": 2,\\n    \"id\": 14,\\n    \"title\": \"voluptatem eligendi optio\",\\n    \"body\": \"fuga et accusamus dolorum perferendis illo voluptas\\\\nnon doloremque neque facere\\\\nad qui dolorum molestiae beatae\\\\nsed aut voluptas totam sit illum\"\\n  },\\n  {\\n    \"userId\": 2,\\n    \"id\": 15,\\n    \"title\": \"eveniet quod temporibus\",\\n    \"body\": \"reprehenderit quos placeat\\\\nvelit minima officia dolores impedit repudiandae molestiae nam\\\\nvoluptas recusandae quis delectus\\\\nofficiis harum fugiat vitae\"\\n  },\\n  {\\n    \"userId\": 2,\\n    \"id\": 16,\\n    \"title\": \"sint suscipit perspiciatis velit dolorum rerum ipsa laboriosam odio\",\\n    \"body\": \"suscipit nam nisi quo aperiam aut\\\\nasperiores eos fugit maiores voluptatibus quia\\\\nvoluptatem quis ullam qui in alias quia est\\\\nconsequatur magni mollitia accusamus ea nisi voluptate dicta\"\\n  },\\n  {\\n    \"userId\": 2,\\n    \"id\": 17,\\n    \"title\": \"fugit voluptas sed molestias voluptatem provident\",\\n    \"body\": \"eos voluptas et aut odit natus earum\\\\naspernatur fuga molestiae ullam\\\\ndeserunt ratione qui eos\\\\nqui nihil ratione nemo velit ut aut id quo\"\\n  },\\n  {\\n    \"userId\": 2,\\n    \"id\": 18,\\n    \"title\": \"voluptate et itaque vero tempora molestiae\",\\n    \"body\": \"eveniet quo quis\\\\nlaborum totam consequatur non dolor\\\\nut et est repudiandae\\\\nest voluptatem vel debitis et magnam\"\\n  },\\n  {\\n    \"userId\": 2,\\n    \"id\": 19,\\n    \"title\": \"adipisci placeat illum aut reiciendis qui\",\\n    \"body\": \"illum quis cupiditate provident sit magnam\\\\nea sed aut omnis\\\\nveniam maiores ullam consequatur atque\\\\nadipisci quo iste expedita sit quos voluptas\"\\n  },\\n  {\\n    \"userId\": 2,\\n    \"id\": 20,\\n    \"title\": \"doloribus ad provident suscipit at\",\\n    \"body\": \"qui consequuntur ducimus possimus quisquam amet similique\\\\nsuscipit porro ipsam amet\\\\neos veritatis officiis exercitationem vel fugit aut necessitatibus totam\\\\nomnis rerum consequatur expedita quidem cumque explicabo\"\\n  },\\n  {\\n    \"userId\": 3,\\n    \"id\": 21,\\n    \"title\": \"asperiores ea ipsam voluptatibus modi minima quia sint\",\\n    \"body\": \"repellat aliquid praesentium dolorem quo\\\\nsed totam minus non itaque\\\\nnihil labore molestiae sunt dolor eveniet hic recusandae veniam\\\\ntempora et tenetur expedita sunt\"\\n  },\\n  {\\n    \"userId\": 3,\\n    \"id\": 22,\\n    \"title\": \"dolor sint quo a velit explicabo quia nam\",\\n    \"body\": \"eos qui et ipsum ipsam suscipit aut\\\\nsed omnis non odio\\\\nexpedita earum mollitia molestiae aut atque rem suscipit\\\\nnam impedit esse\"\\n  },\\n  {\\n    \"userId\": 3,\\n    \"id\": 23,\\n    \"title\": \"maxime id vitae nihil numquam\",\\n    \"body\": \"veritatis unde neque eligendi\\\\nquae quod architecto quo neque vitae\\\\nest illo sit tempora doloremque fugit quod\\\\net et vel beatae sequi ullam sed tenetur perspiciatis\"\\n  },\\n  {\\n    \"userId\": 3,\\n    \"id\": 24,\\n    \"title\": \"autem hic labore sunt dolores incidunt\",\\n    \"body\": \"enim et ex nulla\\\\nomnis voluptas quia qui\\\\nvoluptatem consequatur numquam aliquam sunt\\\\ntotam recusandae id dignissimos aut sed asperiores deserunt\"\\n  },\\n  {\\n    \"userId\": 3,\\n    \"id\": 25,\\n    \"title\": \"rem alias distinctio quo quis\",\\n    \"body\": \"ullam consequatur ut\\\\nomnis quis sit vel consequuntur\\\\nipsa eligendi ipsum molestiae et omnis error nostrum\\\\nmolestiae illo tempore quia et distinctio\"\\n  },\\n  {\\n    \"userId\": 3,\\n    \"id\": 26,\\n    \"title\": \"est et quae odit qui non\",\\n    \"body\": \"similique esse doloribus nihil accusamus\\\\nomnis dolorem fuga consequuntur reprehenderit fugit recusandae temporibus\\\\nperspiciatis cum ut laudantium\\\\nomnis aut molestiae vel vero\"\\n  },\\n  {\\n    \"userId\": 3,\\n    \"id\": 27,\\n    \"title\": \"quasi id et eos tenetur aut quo autem\",\\n    \"body\": \"eum sed dolores ipsam sint possimus debitis occaecati\\\\ndebitis qui qui et\\\\nut placeat enim earum aut odit facilis\\\\nconsequatur suscipit necessitatibus rerum sed inventore temporibus consequatur\"\\n  },\\n  {\\n    \"userId\": 3,\\n    \"id\": 28,\\n    \"title\": \"delectus ullam et corporis nulla voluptas sequi\",\\n    \"body\": \"non et quaerat ex quae ad maiores\\\\nmaiores recusandae totam aut blanditiis mollitia quas illo\\\\nut voluptatibus voluptatem\\\\nsimilique nostrum eum\"\\n  },\\n  {\\n    \"userId\": 3,\\n    \"id\": 29,\\n    \"title\": \"iusto eius quod necessitatibus culpa ea\",\\n    \"body\": \"odit magnam ut saepe sed non qui\\\\ntempora atque nihil\\\\naccusamus illum doloribus illo dolor\\\\neligendi repudiandae odit magni similique sed cum maiores\"\\n  },\\n  {\\n    \"userId\": 3,\\n    \"id\": 30,\\n    \"title\": \"a quo magni similique perferendis\",\\n    \"body\": \"alias dolor cumque\\\\nimpedit blanditiis non eveniet odio maxime\\\\nblanditiis amet eius quis tempora quia autem rem\\\\na provident perspiciatis quia\"\\n  },\\n  {\\n    \"userId\": 4,\\n    \"id\": 31,\\n    \"title\": \"ullam ut quidem id aut vel consequuntur\",\\n    \"body\": \"debitis eius sed quibusdam non quis consectetur vitae\\\\nimpedit ut qui consequatur sed aut in\\\\nquidem sit nostrum et maiores adipisci atque\\\\nquaerat voluptatem adipisci repudiandae\"\\n  },\\n  {\\n    \"userId\": 4,\\n    \"id\": 32,\\n    \"title\": \"doloremque illum aliquid sunt\",\\n    \"body\": \"deserunt eos nobis asperiores et hic\\\\nest debitis repellat molestiae optio\\\\nnihil ratione ut eos beatae quibusdam distinctio maiores\\\\nearum voluptates et aut adipisci ea maiores voluptas maxime\"\\n  },\\n  {\\n    \"userId\": 4,\\n    \"id\": 33,\\n    \"title\": \"qui explicabo molestiae dolorem\",\\n    \"body\": \"rerum ut et numquam laborum odit est sit\\\\nid qui sint in\\\\nquasi tenetur tempore aperiam et quaerat qui in\\\\nrerum officiis sequi cumque quod\"\\n  },\\n  {\\n    \"userId\": 4,\\n    \"id\": 34,\\n    \"title\": \"magnam ut rerum iure\",\\n    \"body\": \"ea velit perferendis earum ut voluptatem voluptate itaque iusto\\\\ntotam pariatur in\\\\nnemo voluptatem voluptatem autem magni tempora minima in\\\\nest distinctio qui assumenda accusamus dignissimos officia nesciunt nobis\"\\n  },\\n  {\\n    \"userId\": 4,\\n    \"id\": 35,\\n    \"title\": \"id nihil consequatur molestias animi provident\",\\n    \"body\": \"nisi error delectus possimus ut eligendi vitae\\\\nplaceat eos harum cupiditate facilis reprehenderit voluptatem beatae\\\\nmodi ducimus quo illum voluptas eligendi\\\\net nobis quia fugit\"\\n  },\\n  {\\n    \"userId\": 4,\\n    \"id\": 36,\\n    \"title\": \"fuga nam accusamus voluptas reiciendis itaque\",\\n    \"body\": \"ad mollitia et omnis minus architecto odit\\\\nvoluptas doloremque maxime aut non ipsa qui alias veniam\\\\nblanditiis culpa aut quia nihil cumque facere et occaecati\\\\nqui aspernatur quia eaque ut aperiam inventore\"\\n  },\\n  {\\n    \"userId\": 4,\\n    \"id\": 37,\\n    \"title\": \"provident vel ut sit ratione est\",\\n    \"body\": \"debitis et eaque non officia sed nesciunt pariatur vel\\\\nvoluptatem iste vero et ea\\\\nnumquam aut expedita ipsum nulla in\\\\nvoluptates omnis consequatur aut enim officiis in quam qui\"\\n  },\\n  {\\n    \"userId\": 4,\\n    \"id\": 38,\\n    \"title\": \"explicabo et eos deleniti nostrum ab id repellendus\",\\n    \"body\": \"animi esse sit aut sit nesciunt assumenda eum voluptas\\\\nquia voluptatibus provident quia necessitatibus ea\\\\nrerum repudiandae quia voluptatem delectus fugit aut id quia\\\\nratione optio eos iusto veniam iure\"\\n  },\\n  {\\n    \"userId\": 4,\\n    \"id\": 39,\\n    \"title\": \"eos dolorem iste accusantium est eaque quam\",\\n    \"body\": \"corporis rerum ducimus vel eum accusantium\\\\nmaxime aspernatur a porro possimus iste omnis\\\\nest in deleniti asperiores fuga aut\\\\nvoluptas sapiente vel dolore minus voluptatem incidunt ex\"\\n  },\\n  {\\n    \"userId\": 4,\\n    \"id\": 40,\\n    \"title\": \"enim quo cumque\",\\n    \"body\": \"ut voluptatum aliquid illo tenetur nemo sequi quo facilis\\\\nipsum rem optio mollitia quas\\\\nvoluptatem eum voluptas qui\\\\nunde omnis voluptatem iure quasi maxime voluptas nam\"\\n  },\\n  {\\n    \"userId\": 5,\\n    \"id\": 41,\\n    \"title\": \"non est facere\",\\n    \"body\": \"molestias id nostrum\\\\nexcepturi molestiae dolore omnis repellendus quaerat saepe\\\\nconsectetur iste quaerat tenetur asperiores accusamus ex ut\\\\nnam quidem est ducimus sunt debitis saepe\"\\n  },\\n  {\\n    \"userId\": 5,\\n    \"id\": 42,\\n    \"title\": \"commodi ullam sint et excepturi error explicabo praesentium voluptas\",\\n    \"body\": \"odio fugit voluptatum ducimus earum autem est incidunt voluptatem\\\\nodit reiciendis aliquam sunt sequi nulla dolorem\\\\nnon facere repellendus voluptates quia\\\\nratione harum vitae ut\"\\n  },\\n  {\\n    \"userId\": 5,\\n    \"id\": 43,\\n    \"title\": \"eligendi iste nostrum consequuntur adipisci praesentium sit beatae perferendis\",\\n    \"body\": \"similique fugit est\\\\nillum et dolorum harum et voluptate eaque quidem\\\\nexercitationem quos nam commodi possimus cum odio nihil nulla\\\\ndolorum exercitationem magnam ex et a et distinctio debitis\"\\n  },\\n  {\\n    \"userId\": 5,\\n    \"id\": 44,\\n    \"title\": \"optio dolor molestias sit\",\\n    \"body\": \"temporibus est consectetur dolore\\\\net libero debitis vel velit laboriosam quia\\\\nipsum quibusdam qui itaque fuga rem aut\\\\nea et iure quam sed maxime ut distinctio quae\"\\n  },\\n  {\\n    \"userId\": 5,\\n    \"id\": 45,\\n    \"title\": \"ut numquam possimus omnis eius suscipit laudantium iure\",\\n    \"body\": \"est natus reiciendis nihil possimus aut provident\\\\nex et dolor\\\\nrepellat pariatur est\\\\nnobis rerum repellendus dolorem autem\"\\n  },\\n  {\\n    \"userId\": 5,\\n    \"id\": 46,\\n    \"title\": \"aut quo modi neque nostrum ducimus\",\\n    \"body\": \"voluptatem quisquam iste\\\\nvoluptatibus natus officiis facilis dolorem\\\\nquis quas ipsam\\\\nvel et voluptatum in aliquid\"\\n  },\\n  {\\n    \"userId\": 5,\\n    \"id\": 47,\\n    \"title\": \"quibusdam cumque rem aut deserunt\",\\n    \"body\": \"voluptatem assumenda ut qui ut cupiditate aut impedit veniam\\\\noccaecati nemo illum voluptatem laudantium\\\\nmolestiae beatae rerum ea iure soluta nostrum\\\\neligendi et voluptate\"\\n  },\\n  {\\n    \"userId\": 5,\\n    \"id\": 48,\\n    \"title\": \"ut voluptatem illum ea doloribus itaque eos\",\\n    \"body\": \"voluptates quo voluptatem facilis iure occaecati\\\\nvel assumenda rerum officia et\\\\nillum perspiciatis ab deleniti\\\\nlaudantium repellat ad ut et autem reprehenderit\"\\n  },\\n  {\\n    \"userId\": 5,\\n    \"id\": 49,\\n    \"title\": \"laborum non sunt aut ut assumenda perspiciatis voluptas\",\\n    \"body\": \"inventore ab sint\\\\nnatus fugit id nulla sequi architecto nihil quaerat\\\\neos tenetur in in eum veritatis non\\\\nquibusdam officiis aspernatur cumque aut commodi aut\"\\n  },\\n  {\\n    \"userId\": 5,\\n    \"id\": 50,\\n    \"title\": \"repellendus qui recusandae incidunt voluptates tenetur qui omnis exercitationem\",\\n    \"body\": \"error suscipit maxime adipisci consequuntur recusandae\\\\nvoluptas eligendi et est et voluptates\\\\nquia distinctio ab amet quaerat molestiae et vitae\\\\nadipisci impedit sequi nesciunt quis consectetur\"\\n  },\\n  {\\n    \"userId\": 6,\\n    \"id\": 51,\\n    \"title\": \"soluta aliquam aperiam consequatur illo quis voluptas\",\\n    \"body\": \"sunt dolores aut doloribus\\\\ndolore doloribus voluptates tempora et\\\\ndoloremque et quo\\\\ncum asperiores sit consectetur dolorem\"\\n  },\\n  {\\n    \"userId\": 6,\\n    \"id\": 52,\\n    \"title\": \"qui enim et consequuntur quia animi quis voluptate quibusdam\",\\n    \"body\": \"iusto est quibusdam fuga quas quaerat molestias\\\\na enim ut sit accusamus enim\\\\ntemporibus iusto accusantium provident architecto\\\\nsoluta esse reprehenderit qui laborum\"\\n  },\\n  {\\n    \"userId\": 6,\\n    \"id\": 53,\\n    \"title\": \"ut quo aut ducimus alias\",\\n    \"body\": \"minima harum praesentium eum rerum illo dolore\\\\nquasi exercitationem rerum nam\\\\nporro quis neque quo\\\\nconsequatur minus dolor quidem veritatis sunt non explicabo similique\"\\n  },\\n  {\\n    \"userId\": 6,\\n    \"id\": 54,\\n    \"title\": \"sit asperiores ipsam eveniet odio non quia\",\\n    \"body\": \"totam corporis dignissimos\\\\nvitae dolorem ut occaecati accusamus\\\\nex velit deserunt\\\\net exercitationem vero incidunt corrupti mollitia\"\\n  },\\n  {\\n    \"userId\": 6,\\n    \"id\": 55,\\n    \"title\": \"sit vel voluptatem et non libero\",\\n    \"body\": \"debitis excepturi ea perferendis harum libero optio\\\\neos accusamus cum fuga ut sapiente repudiandae\\\\net ut incidunt omnis molestiae\\\\nnihil ut eum odit\"\\n  },\\n  {\\n    \"userId\": 6,\\n    \"id\": 56,\\n    \"title\": \"qui et at rerum necessitatibus\",\\n    \"body\": \"aut est omnis dolores\\\\nneque rerum quod ea rerum velit pariatur beatae excepturi\\\\net provident voluptas corrupti\\\\ncorporis harum reprehenderit dolores eligendi\"\\n  },\\n  {\\n    \"userId\": 6,\\n    \"id\": 57,\\n    \"title\": \"sed ab est est\",\\n    \"body\": \"at pariatur consequuntur earum quidem\\\\nquo est laudantium soluta voluptatem\\\\nqui ullam et est\\\\net cum voluptas voluptatum repellat est\"\\n  },\\n  {\\n    \"userId\": 6,\\n    \"id\": 58,\\n    \"title\": \"voluptatum itaque dolores nisi et quasi\",\\n    \"body\": \"veniam voluptatum quae adipisci id\\\\net id quia eos ad et dolorem\\\\naliquam quo nisi sunt eos impedit error\\\\nad similique veniam\"\\n  },\\n  {\\n    \"userId\": 6,\\n    \"id\": 59,\\n    \"title\": \"qui commodi dolor at maiores et quis id accusantium\",\\n    \"body\": \"perspiciatis et quam ea autem temporibus non voluptatibus qui\\\\nbeatae a earum officia nesciunt dolores suscipit voluptas et\\\\nanimi doloribus cum rerum quas et magni\\\\net hic ut ut commodi expedita sunt\"\\n  },\\n  {\\n    \"userId\": 6,\\n    \"id\": 60,\\n    \"title\": \"consequatur placeat omnis quisquam quia reprehenderit fugit veritatis facere\",\\n    \"body\": \"asperiores sunt ab assumenda cumque modi velit\\\\nqui esse omnis\\\\nvoluptate et fuga perferendis voluptas\\\\nillo ratione amet aut et omnis\"\\n  },\\n  {\\n    \"userId\": 7,\\n    \"id\": 61,\\n    \"title\": \"voluptatem doloribus consectetur est ut ducimus\",\\n    \"body\": \"ab nemo optio odio\\\\ndelectus tenetur corporis similique nobis repellendus rerum omnis facilis\\\\nvero blanditiis debitis in nesciunt doloribus dicta dolores\\\\nmagnam minus velit\"\\n  },\\n  {\\n    \"userId\": 7,\\n    \"id\": 62,\\n    \"title\": \"beatae enim quia vel\",\\n    \"body\": \"enim aspernatur illo distinctio quae praesentium\\\\nbeatae alias amet delectus qui voluptate distinctio\\\\nodit sint accusantium autem omnis\\\\nquo molestiae omnis ea eveniet optio\"\\n  },\\n  {\\n    \"userId\": 7,\\n    \"id\": 63,\\n    \"title\": \"voluptas blanditiis repellendus animi ducimus error sapiente et suscipit\",\\n    \"body\": \"enim adipisci aspernatur nemo\\\\nnumquam omnis facere dolorem dolor ex quis temporibus incidunt\\\\nab delectus culpa quo reprehenderit blanditiis asperiores\\\\naccusantium ut quam in voluptatibus voluptas ipsam dicta\"\\n  },\\n  {\\n    \"userId\": 7,\\n    \"id\": 64,\\n    \"title\": \"et fugit quas eum in in aperiam quod\",\\n    \"body\": \"id velit blanditiis\\\\neum ea voluptatem\\\\nmolestiae sint occaecati est eos perspiciatis\\\\nincidunt a error provident eaque aut aut qui\"\\n  },\\n  {\\n    \"userId\": 7,\\n    \"id\": 65,\\n    \"title\": \"consequatur id enim sunt et et\",\\n    \"body\": \"voluptatibus ex esse\\\\nsint explicabo est aliquid cumque adipisci fuga repellat labore\\\\nmolestiae corrupti ex saepe at asperiores et perferendis\\\\nnatus id esse incidunt pariatur\"\\n  },\\n  {\\n    \"userId\": 7,\\n    \"id\": 66,\\n    \"title\": \"repudiandae ea animi iusto\",\\n    \"body\": \"officia veritatis tenetur vero qui itaque\\\\nsint non ratione\\\\nsed et ut asperiores iusto eos molestiae nostrum\\\\nveritatis quibusdam et nemo iusto saepe\"\\n  },\\n  {\\n    \"userId\": 7,\\n    \"id\": 67,\\n    \"title\": \"aliquid eos sed fuga est maxime repellendus\",\\n    \"body\": \"reprehenderit id nostrum\\\\nvoluptas doloremque pariatur sint et accusantium quia quod aspernatur\\\\net fugiat amet\\\\nnon sapiente et consequatur necessitatibus molestiae\"\\n  },\\n  {\\n    \"userId\": 7,\\n    \"id\": 68,\\n    \"title\": \"odio quis facere architecto reiciendis optio\",\\n    \"body\": \"magnam molestiae perferendis quisquam\\\\nqui cum reiciendis\\\\nquaerat animi amet hic inventore\\\\nea quia deleniti quidem saepe porro velit\"\\n  },\\n  {\\n    \"userId\": 7,\\n    \"id\": 69,\\n    \"title\": \"fugiat quod pariatur odit minima\",\\n    \"body\": \"officiis error culpa consequatur modi asperiores et\\\\ndolorum assumenda voluptas et vel qui aut vel rerum\\\\nvoluptatum quisquam perspiciatis quia rerum consequatur totam quas\\\\nsequi commodi repudiandae asperiores et saepe a\"\\n  },\\n  {\\n    \"userId\": 7,\\n    \"id\": 70,\\n    \"title\": \"voluptatem laborum magni\",\\n    \"body\": \"sunt repellendus quae\\\\nest asperiores aut deleniti esse accusamus repellendus quia aut\\\\nquia dolorem unde\\\\neum tempora esse dolore\"\\n  },\\n  {\\n    \"userId\": 8,\\n    \"id\": 71,\\n    \"title\": \"et iusto veniam et illum aut fuga\",\\n    \"body\": \"occaecati a doloribus\\\\niste saepe consectetur placeat eum voluptate dolorem et\\\\nqui quo quia voluptas\\\\nrerum ut id enim velit est perferendis\"\\n  },\\n  {\\n    \"userId\": 8,\\n    \"id\": 72,\\n    \"title\": \"sint hic doloribus consequatur eos non id\",\\n    \"body\": \"quam occaecati qui deleniti consectetur\\\\nconsequatur aut facere quas exercitationem aliquam hic voluptas\\\\nneque id sunt ut aut accusamus\\\\nsunt consectetur expedita inventore velit\"\\n  },\\n  {\\n    \"userId\": 8,\\n    \"id\": 73,\\n    \"title\": \"consequuntur deleniti eos quia temporibus ab aliquid at\",\\n    \"body\": \"voluptatem cumque tenetur consequatur expedita ipsum nemo quia explicabo\\\\naut eum minima consequatur\\\\ntempore cumque quae est et\\\\net in consequuntur voluptatem voluptates aut\"\\n  },\\n  {\\n    \"userId\": 8,\\n    \"id\": 74,\\n    \"title\": \"enim unde ratione doloribus quas enim ut sit sapiente\",\\n    \"body\": \"odit qui et et necessitatibus sint veniam\\\\nmollitia amet doloremque molestiae commodi similique magnam et quam\\\\nblanditiis est itaque\\\\nquo et tenetur ratione occaecati molestiae tempora\"\\n  },\\n  {\\n    \"userId\": 8,\\n    \"id\": 75,\\n    \"title\": \"dignissimos eum dolor ut enim et delectus in\",\\n    \"body\": \"commodi non non omnis et voluptas sit\\\\nautem aut nobis magnam et sapiente voluptatem\\\\net laborum repellat qui delectus facilis temporibus\\\\nrerum amet et nemo voluptate expedita adipisci error dolorem\"\\n  },\\n  {\\n    \"userId\": 8,\\n    \"id\": 76,\\n    \"title\": \"doloremque officiis ad et non perferendis\",\\n    \"body\": \"ut animi facere\\\\ntotam iusto tempore\\\\nmolestiae eum aut et dolorem aperiam\\\\nquaerat recusandae totam odio\"\\n  },\\n  {\\n    \"userId\": 8,\\n    \"id\": 77,\\n    \"title\": \"necessitatibus quasi exercitationem odio\",\\n    \"body\": \"modi ut in nulla repudiandae dolorum nostrum eos\\\\naut consequatur omnis\\\\nut incidunt est omnis iste et quam\\\\nvoluptates sapiente aliquam asperiores nobis amet corrupti repudiandae provident\"\\n  },\\n  {\\n    \"userId\": 8,\\n    \"id\": 78,\\n    \"title\": \"quam voluptatibus rerum veritatis\",\\n    \"body\": \"nobis facilis odit tempore cupiditate quia\\\\nassumenda doloribus rerum qui ea\\\\nillum et qui totam\\\\naut veniam repellendus\"\\n  },\\n  {\\n    \"userId\": 8,\\n    \"id\": 79,\\n    \"title\": \"pariatur consequatur quia magnam autem omnis non amet\",\\n    \"body\": \"libero accusantium et et facere incidunt sit dolorem\\\\nnon excepturi qui quia sed laudantium\\\\nquisquam molestiae ducimus est\\\\nofficiis esse molestiae iste et quos\"\\n  },\\n  {\\n    \"userId\": 8,\\n    \"id\": 80,\\n    \"title\": \"labore in ex et explicabo corporis aut quas\",\\n    \"body\": \"ex quod dolorem ea eum iure qui provident amet\\\\nquia qui facere excepturi et repudiandae\\\\nasperiores molestias provident\\\\nminus incidunt vero fugit rerum sint sunt excepturi provident\"\\n  },\\n  {\\n    \"userId\": 9,\\n    \"id\": 81,\\n    \"title\": \"tempora rem veritatis voluptas quo dolores vero\",\\n    \"body\": \"facere qui nesciunt est voluptatum voluptatem nisi\\\\nsequi eligendi necessitatibus ea at rerum itaque\\\\nharum non ratione velit laboriosam quis consequuntur\\\\nex officiis minima doloremque voluptas ut aut\"\\n  },\\n  {\\n    \"userId\": 9,\\n    \"id\": 82,\\n    \"title\": \"laudantium voluptate suscipit sunt enim enim\",\\n    \"body\": \"ut libero sit aut totam inventore sunt\\\\nporro sint qui sunt molestiae\\\\nconsequatur cupiditate qui iste ducimus adipisci\\\\ndolor enim assumenda soluta laboriosam amet iste delectus hic\"\\n  },\\n  {\\n    \"userId\": 9,\\n    \"id\": 83,\\n    \"title\": \"odit et voluptates doloribus alias odio et\",\\n    \"body\": \"est molestiae facilis quis tempora numquam nihil qui\\\\nvoluptate sapiente consequatur est qui\\\\nnecessitatibus autem aut ipsa aperiam modi dolore numquam\\\\nreprehenderit eius rem quibusdam\"\\n  },\\n  {\\n    \"userId\": 9,\\n    \"id\": 84,\\n    \"title\": \"optio ipsam molestias necessitatibus occaecati facilis veritatis dolores aut\",\\n    \"body\": \"sint molestiae magni a et quos\\\\neaque et quasi\\\\nut rerum debitis similique veniam\\\\nrecusandae dignissimos dolor incidunt consequatur odio\"\\n  },\\n  {\\n    \"userId\": 9,\\n    \"id\": 85,\\n    \"title\": \"dolore veritatis porro provident adipisci blanditiis et sunt\",\\n    \"body\": \"similique sed nisi voluptas iusto omnis\\\\nmollitia et quo\\\\nassumenda suscipit officia magnam sint sed tempora\\\\nenim provident pariatur praesentium atque animi amet ratione\"\\n  },\\n  {\\n    \"userId\": 9,\\n    \"id\": 86,\\n    \"title\": \"placeat quia et porro iste\",\\n    \"body\": \"quasi excepturi consequatur iste autem temporibus sed molestiae beatae\\\\net quaerat et esse ut\\\\nvoluptatem occaecati et vel explicabo autem\\\\nasperiores pariatur deserunt optio\"\\n  },\\n  {\\n    \"userId\": 9,\\n    \"id\": 87,\\n    \"title\": \"nostrum quis quasi placeat\",\\n    \"body\": \"eos et molestiae\\\\nnesciunt ut a\\\\ndolores perspiciatis repellendus repellat aliquid\\\\nmagnam sint rem ipsum est\"\\n  },\\n  {\\n    \"userId\": 9,\\n    \"id\": 88,\\n    \"title\": \"sapiente omnis fugit eos\",\\n    \"body\": \"consequatur omnis est praesentium\\\\nducimus non iste\\\\nneque hic deserunt\\\\nvoluptatibus veniam cum et rerum sed\"\\n  },\\n  {\\n    \"userId\": 9,\\n    \"id\": 89,\\n    \"title\": \"sint soluta et vel magnam aut ut sed qui\",\\n    \"body\": \"repellat aut aperiam totam temporibus autem et\\\\narchitecto magnam ut\\\\nconsequatur qui cupiditate rerum quia soluta dignissimos nihil iure\\\\ntempore quas est\"\\n  },\\n  {\\n    \"userId\": 9,\\n    \"id\": 90,\\n    \"title\": \"ad iusto omnis odit dolor voluptatibus\",\\n    \"body\": \"minus omnis soluta quia\\\\nqui sed adipisci voluptates illum ipsam voluptatem\\\\neligendi officia ut in\\\\neos soluta similique molestias praesentium blanditiis\"\\n  },\\n  {\\n    \"userId\": 10,\\n    \"id\": 91,\\n    \"title\": \"aut amet sed\",\\n    \"body\": \"libero voluptate eveniet aperiam sed\\\\nsunt placeat suscipit molestias\\\\nsimilique fugit nam natus\\\\nexpedita consequatur consequatur dolores quia eos et placeat\"\\n  },\\n  {\\n    \"userId\": 10,\\n    \"id\": 92,\\n    \"title\": \"ratione ex tenetur perferendis\",\\n    \"body\": \"aut et excepturi dicta laudantium sint rerum nihil\\\\nlaudantium et at\\\\na neque minima officia et similique libero et\\\\ncommodi voluptate qui\"\\n  },\\n  {\\n    \"userId\": 10,\\n    \"id\": 93,\\n    \"title\": \"beatae soluta recusandae\",\\n    \"body\": \"dolorem quibusdam ducimus consequuntur dicta aut quo laboriosam\\\\nvoluptatem quis enim recusandae ut sed sunt\\\\nnostrum est odit totam\\\\nsit error sed sunt eveniet provident qui nulla\"\\n  },\\n  {\\n    \"userId\": 10,\\n    \"id\": 94,\\n    \"title\": \"qui qui voluptates illo iste minima\",\\n    \"body\": \"aspernatur expedita soluta quo ab ut similique\\\\nexpedita dolores amet\\\\nsed temporibus distinctio magnam saepe deleniti\\\\nomnis facilis nam ipsum natus sint similique omnis\"\\n  },\\n  {\\n    \"userId\": 10,\\n    \"id\": 95,\\n    \"title\": \"id minus libero illum nam ad officiis\",\\n    \"body\": \"earum voluptatem facere provident blanditiis velit laboriosam\\\\npariatur accusamus odio saepe\\\\ncumque dolor qui a dicta ab doloribus consequatur omnis\\\\ncorporis cupiditate eaque assumenda ad nesciunt\"\\n  },\\n  {\\n    \"userId\": 10,\\n    \"id\": 96,\\n    \"title\": \"quaerat velit veniam amet cupiditate aut numquam ut sequi\",\\n    \"body\": \"in non odio excepturi sint eum\\\\nlabore voluptates vitae quia qui et\\\\ninventore itaque rerum\\\\nveniam non exercitationem delectus aut\"\\n  },\\n  {\\n    \"userId\": 10,\\n    \"id\": 97,\\n    \"title\": \"quas fugiat ut perspiciatis vero provident\",\\n    \"body\": \"eum non blanditiis soluta porro quibusdam voluptas\\\\nvel voluptatem qui placeat dolores qui velit aut\\\\nvel inventore aut cumque culpa explicabo aliquid at\\\\nperspiciatis est et voluptatem dignissimos dolor itaque sit nam\"\\n  },\\n  {\\n    \"userId\": 10,\\n    \"id\": 98,\\n    \"title\": \"laboriosam dolor voluptates\",\\n    \"body\": \"doloremque ex facilis sit sint culpa\\\\nsoluta assumenda eligendi non ut eius\\\\nsequi ducimus vel quasi\\\\nveritatis est dolores\"\\n  },\\n  {\\n    \"userId\": 10,\\n    \"id\": 99,\\n    \"title\": \"temporibus sit alias delectus eligendi possimus magni\",\\n    \"body\": \"quo deleniti praesentium dicta non quod\\\\naut est molestias\\\\nmolestias et officia quis nihil\\\\nitaque dolorem quia\"\\n  },\\n  {\\n    \"userId\": 10,\\n    \"id\": 100,\\n    \"title\": \"at nam consequatur ea labore ea harum\",\\n    \"body\": \"cupiditate quo est a modi nesciunt soluta\\\\nipsa voluptas error itaque dicta in\\\\nautem qui minus magnam et distinctio eum\\\\naccusamus ratione error aut\"\\n  }\\n]'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts = requests.get(\"https://jsonplaceholder.typicode.com/posts\")\n",
    "posts.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>sunt aut facere repellat provident occaecati e...</td>\n",
       "      <td>quia et suscipit\\nsuscipit recusandae consequu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>qui est esse</td>\n",
       "      <td>est rerum tempore vitae\\nsequi sint nihil repr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>ea molestias quasi exercitationem repellat qui...</td>\n",
       "      <td>et iusto sed quo iure\\nvoluptatem occaecati om...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>eum et est occaecati</td>\n",
       "      <td>ullam et saepe reiciendis voluptatem adipisci\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>nesciunt quas odio</td>\n",
       "      <td>repudiandae veniam quaerat sunt sed\\nalias aut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>10</td>\n",
       "      <td>96</td>\n",
       "      <td>quaerat velit veniam amet cupiditate aut numqu...</td>\n",
       "      <td>in non odio excepturi sint eum\\nlabore volupta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>10</td>\n",
       "      <td>97</td>\n",
       "      <td>quas fugiat ut perspiciatis vero provident</td>\n",
       "      <td>eum non blanditiis soluta porro quibusdam volu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>10</td>\n",
       "      <td>98</td>\n",
       "      <td>laboriosam dolor voluptates</td>\n",
       "      <td>doloremque ex facilis sit sint culpa\\nsoluta a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>10</td>\n",
       "      <td>99</td>\n",
       "      <td>temporibus sit alias delectus eligendi possimu...</td>\n",
       "      <td>quo deleniti praesentium dicta non quod\\naut e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>at nam consequatur ea labore ea harum</td>\n",
       "      <td>cupiditate quo est a modi nesciunt soluta\\nips...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    userId   id                                              title  \\\n",
       "0        1    1  sunt aut facere repellat provident occaecati e...   \n",
       "1        1    2                                       qui est esse   \n",
       "2        1    3  ea molestias quasi exercitationem repellat qui...   \n",
       "3        1    4                               eum et est occaecati   \n",
       "4        1    5                                 nesciunt quas odio   \n",
       "..     ...  ...                                                ...   \n",
       "95      10   96  quaerat velit veniam amet cupiditate aut numqu...   \n",
       "96      10   97         quas fugiat ut perspiciatis vero provident   \n",
       "97      10   98                        laboriosam dolor voluptates   \n",
       "98      10   99  temporibus sit alias delectus eligendi possimu...   \n",
       "99      10  100              at nam consequatur ea labore ea harum   \n",
       "\n",
       "                                                 body  \n",
       "0   quia et suscipit\\nsuscipit recusandae consequu...  \n",
       "1   est rerum tempore vitae\\nsequi sint nihil repr...  \n",
       "2   et iusto sed quo iure\\nvoluptatem occaecati om...  \n",
       "3   ullam et saepe reiciendis voluptatem adipisci\\...  \n",
       "4   repudiandae veniam quaerat sunt sed\\nalias aut...  \n",
       "..                                                ...  \n",
       "95  in non odio excepturi sint eum\\nlabore volupta...  \n",
       "96  eum non blanditiis soluta porro quibusdam volu...  \n",
       "97  doloremque ex facilis sit sint culpa\\nsoluta a...  \n",
       "98  quo deleniti praesentium dicta non quod\\naut e...  \n",
       "99  cupiditate quo est a modi nesciunt soluta\\nips...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df = pd.read_json(posts.text)\n",
    "posts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Situation 2: Nesting, but no metadata\n",
    "\n",
    "If the JSON file contains nesting, but no metadata, then the best strategy is to\n",
    "\n",
    "1. Use `requests.get()` to download the raw JSON data (unless you have another way of acquiring the raw data)\n",
    "\n",
    "2. Use `json.loads()` on the `.text` attribute of the output from step 1 to register the data as a list in Python\n",
    "\n",
    "3. Use the `pd.json_normalize()` function on the list that is the output of step 2\n",
    "\n",
    "The `pd.json_normalize()` function stores every feature in the data in a separate column, no matter how many levels of nesting it must parse to find the feature. \n",
    "\n",
    "Every column has the same name as the key from which it drew the feature. For features that are nested within other features, `pd.json_normalize()` uses every key on the path to the datapoint to construct the column name, separated by periods. For example, the `users` data that we worked with above contains up to three levels of nesting. So the `lat` data is stored in a column named `address.geo.lat`, since we had to navigate to \"address\", then \"geo\", then \"lat\" in the JSON to find these data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n  {\\n    \"id\": 1,\\n    \"name\": \"Leanne Graham\",\\n    \"username\": \"Bret\",\\n    \"email\": \"Sincere@april.biz\",\\n    \"address\": {\\n      \"street\": \"Kulas Light\",\\n      \"suite\": \"Apt. 556\",\\n      \"city\": \"Gwenborough\",\\n      \"zipcode\": \"92998-3874\",\\n      \"geo\": {\\n        \"lat\": \"-37.3159\",\\n        \"lng\": \"81.1496\"\\n      }\\n    },\\n    \"phone\": \"1-770-736-8031 x56442\",\\n    \"website\": \"hildegard.org\",\\n    \"company\": {\\n      \"name\": \"Romaguera-Crona\",\\n      \"catchPhrase\": \"Multi-layered client-server neural-net\",\\n      \"bs\": \"harness real-time e-markets\"\\n    }\\n  },\\n  {\\n    \"id\": 2,\\n    \"name\": \"Ervin Howell\",\\n    \"username\": \"Antonette\",\\n    \"email\": \"Shanna@melissa.tv\",\\n    \"address\": {\\n      \"street\": \"Victor Plains\",\\n      \"suite\": \"Suite 879\",\\n      \"city\": \"Wisokyburgh\",\\n      \"zipcode\": \"90566-7771\",\\n      \"geo\": {\\n        \"lat\": \"-43.9509\",\\n        \"lng\": \"-34.4618\"\\n      }\\n    },\\n    \"phone\": \"010-692-6593 x09125\",\\n    \"website\": \"anastasia.net\",\\n    \"company\": {\\n      \"name\": \"Deckow-Crist\",\\n      \"catchPhrase\": \"Proactive didactic contingency\",\\n      \"bs\": \"synergize scalable supply-chains\"\\n    }\\n  },\\n  {\\n    \"id\": 3,\\n    \"name\": \"Clementine Bauch\",\\n    \"username\": \"Samantha\",\\n    \"email\": \"Nathan@yesenia.net\",\\n    \"address\": {\\n      \"street\": \"Douglas Extension\",\\n      \"suite\": \"Suite 847\",\\n      \"city\": \"McKenziehaven\",\\n      \"zipcode\": \"59590-4157\",\\n      \"geo\": {\\n        \"lat\": \"-68.6102\",\\n        \"lng\": \"-47.0653\"\\n      }\\n    },\\n    \"phone\": \"1-463-123-4447\",\\n    \"website\": \"ramiro.info\",\\n    \"company\": {\\n      \"name\": \"Romaguera-Jacobson\",\\n      \"catchPhrase\": \"Face to face bifurcated interface\",\\n      \"bs\": \"e-enable strategic applications\"\\n    }\\n  },\\n  {\\n    \"id\": 4,\\n    \"name\": \"Patricia Lebsack\",\\n    \"username\": \"Karianne\",\\n    \"email\": \"Julianne.OConner@kory.org\",\\n    \"address\": {\\n      \"street\": \"Hoeger Mall\",\\n      \"suite\": \"Apt. 692\",\\n      \"city\": \"South Elvis\",\\n      \"zipcode\": \"53919-4257\",\\n      \"geo\": {\\n        \"lat\": \"29.4572\",\\n        \"lng\": \"-164.2990\"\\n      }\\n    },\\n    \"phone\": \"493-170-9623 x156\",\\n    \"website\": \"kale.biz\",\\n    \"company\": {\\n      \"name\": \"Robel-Corkery\",\\n      \"catchPhrase\": \"Multi-tiered zero tolerance productivity\",\\n      \"bs\": \"transition cutting-edge web services\"\\n    }\\n  },\\n  {\\n    \"id\": 5,\\n    \"name\": \"Chelsey Dietrich\",\\n    \"username\": \"Kamren\",\\n    \"email\": \"Lucio_Hettinger@annie.ca\",\\n    \"address\": {\\n      \"street\": \"Skiles Walks\",\\n      \"suite\": \"Suite 351\",\\n      \"city\": \"Roscoeview\",\\n      \"zipcode\": \"33263\",\\n      \"geo\": {\\n        \"lat\": \"-31.8129\",\\n        \"lng\": \"62.5342\"\\n      }\\n    },\\n    \"phone\": \"(254)954-1289\",\\n    \"website\": \"demarco.info\",\\n    \"company\": {\\n      \"name\": \"Keebler LLC\",\\n      \"catchPhrase\": \"User-centric fault-tolerant solution\",\\n      \"bs\": \"revolutionize end-to-end systems\"\\n    }\\n  },\\n  {\\n    \"id\": 6,\\n    \"name\": \"Mrs. Dennis Schulist\",\\n    \"username\": \"Leopoldo_Corkery\",\\n    \"email\": \"Karley_Dach@jasper.info\",\\n    \"address\": {\\n      \"street\": \"Norberto Crossing\",\\n      \"suite\": \"Apt. 950\",\\n      \"city\": \"South Christy\",\\n      \"zipcode\": \"23505-1337\",\\n      \"geo\": {\\n        \"lat\": \"-71.4197\",\\n        \"lng\": \"71.7478\"\\n      }\\n    },\\n    \"phone\": \"1-477-935-8478 x6430\",\\n    \"website\": \"ola.org\",\\n    \"company\": {\\n      \"name\": \"Considine-Lockman\",\\n      \"catchPhrase\": \"Synchronised bottom-line interface\",\\n      \"bs\": \"e-enable innovative applications\"\\n    }\\n  },\\n  {\\n    \"id\": 7,\\n    \"name\": \"Kurtis Weissnat\",\\n    \"username\": \"Elwyn.Skiles\",\\n    \"email\": \"Telly.Hoeger@billy.biz\",\\n    \"address\": {\\n      \"street\": \"Rex Trail\",\\n      \"suite\": \"Suite 280\",\\n      \"city\": \"Howemouth\",\\n      \"zipcode\": \"58804-1099\",\\n      \"geo\": {\\n        \"lat\": \"24.8918\",\\n        \"lng\": \"21.8984\"\\n      }\\n    },\\n    \"phone\": \"210.067.6132\",\\n    \"website\": \"elvis.io\",\\n    \"company\": {\\n      \"name\": \"Johns Group\",\\n      \"catchPhrase\": \"Configurable multimedia task-force\",\\n      \"bs\": \"generate enterprise e-tailers\"\\n    }\\n  },\\n  {\\n    \"id\": 8,\\n    \"name\": \"Nicholas Runolfsdottir V\",\\n    \"username\": \"Maxime_Nienow\",\\n    \"email\": \"Sherwood@rosamond.me\",\\n    \"address\": {\\n      \"street\": \"Ellsworth Summit\",\\n      \"suite\": \"Suite 729\",\\n      \"city\": \"Aliyaview\",\\n      \"zipcode\": \"45169\",\\n      \"geo\": {\\n        \"lat\": \"-14.3990\",\\n        \"lng\": \"-120.7677\"\\n      }\\n    },\\n    \"phone\": \"586.493.6943 x140\",\\n    \"website\": \"jacynthe.com\",\\n    \"company\": {\\n      \"name\": \"Abernathy Group\",\\n      \"catchPhrase\": \"Implemented secondary concept\",\\n      \"bs\": \"e-enable extensible e-tailers\"\\n    }\\n  },\\n  {\\n    \"id\": 9,\\n    \"name\": \"Glenna Reichert\",\\n    \"username\": \"Delphine\",\\n    \"email\": \"Chaim_McDermott@dana.io\",\\n    \"address\": {\\n      \"street\": \"Dayna Park\",\\n      \"suite\": \"Suite 449\",\\n      \"city\": \"Bartholomebury\",\\n      \"zipcode\": \"76495-3109\",\\n      \"geo\": {\\n        \"lat\": \"24.6463\",\\n        \"lng\": \"-168.8889\"\\n      }\\n    },\\n    \"phone\": \"(775)976-6794 x41206\",\\n    \"website\": \"conrad.com\",\\n    \"company\": {\\n      \"name\": \"Yost and Sons\",\\n      \"catchPhrase\": \"Switchable contextually-based project\",\\n      \"bs\": \"aggregate real-time technologies\"\\n    }\\n  },\\n  {\\n    \"id\": 10,\\n    \"name\": \"Clementina DuBuque\",\\n    \"username\": \"Moriah.Stanton\",\\n    \"email\": \"Rey.Padberg@karina.biz\",\\n    \"address\": {\\n      \"street\": \"Kattie Turnpike\",\\n      \"suite\": \"Suite 198\",\\n      \"city\": \"Lebsackbury\",\\n      \"zipcode\": \"31428-2261\",\\n      \"geo\": {\\n        \"lat\": \"-38.2386\",\\n        \"lng\": \"57.2232\"\\n      }\\n    },\\n    \"phone\": \"024-648-3804\",\\n    \"website\": \"ambrose.net\",\\n    \"company\": {\\n      \"name\": \"Hoeger LLC\",\\n      \"catchPhrase\": \"Centralized empowering task-force\",\\n      \"bs\": \"target end-to-end models\"\\n    }\\n  }\\n]'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = requests.get(\"https://jsonplaceholder.typicode.com/users\")\n",
    "users.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'name': 'Leanne Graham',\n",
       "  'username': 'Bret',\n",
       "  'email': 'Sincere@april.biz',\n",
       "  'address': {'street': 'Kulas Light',\n",
       "   'suite': 'Apt. 556',\n",
       "   'city': 'Gwenborough',\n",
       "   'zipcode': '92998-3874',\n",
       "   'geo': {'lat': '-37.3159', 'lng': '81.1496'}},\n",
       "  'phone': '1-770-736-8031 x56442',\n",
       "  'website': 'hildegard.org',\n",
       "  'company': {'name': 'Romaguera-Crona',\n",
       "   'catchPhrase': 'Multi-layered client-server neural-net',\n",
       "   'bs': 'harness real-time e-markets'}},\n",
       " {'id': 2,\n",
       "  'name': 'Ervin Howell',\n",
       "  'username': 'Antonette',\n",
       "  'email': 'Shanna@melissa.tv',\n",
       "  'address': {'street': 'Victor Plains',\n",
       "   'suite': 'Suite 879',\n",
       "   'city': 'Wisokyburgh',\n",
       "   'zipcode': '90566-7771',\n",
       "   'geo': {'lat': '-43.9509', 'lng': '-34.4618'}},\n",
       "  'phone': '010-692-6593 x09125',\n",
       "  'website': 'anastasia.net',\n",
       "  'company': {'name': 'Deckow-Crist',\n",
       "   'catchPhrase': 'Proactive didactic contingency',\n",
       "   'bs': 'synergize scalable supply-chains'}},\n",
       " {'id': 3,\n",
       "  'name': 'Clementine Bauch',\n",
       "  'username': 'Samantha',\n",
       "  'email': 'Nathan@yesenia.net',\n",
       "  'address': {'street': 'Douglas Extension',\n",
       "   'suite': 'Suite 847',\n",
       "   'city': 'McKenziehaven',\n",
       "   'zipcode': '59590-4157',\n",
       "   'geo': {'lat': '-68.6102', 'lng': '-47.0653'}},\n",
       "  'phone': '1-463-123-4447',\n",
       "  'website': 'ramiro.info',\n",
       "  'company': {'name': 'Romaguera-Jacobson',\n",
       "   'catchPhrase': 'Face to face bifurcated interface',\n",
       "   'bs': 'e-enable strategic applications'}},\n",
       " {'id': 4,\n",
       "  'name': 'Patricia Lebsack',\n",
       "  'username': 'Karianne',\n",
       "  'email': 'Julianne.OConner@kory.org',\n",
       "  'address': {'street': 'Hoeger Mall',\n",
       "   'suite': 'Apt. 692',\n",
       "   'city': 'South Elvis',\n",
       "   'zipcode': '53919-4257',\n",
       "   'geo': {'lat': '29.4572', 'lng': '-164.2990'}},\n",
       "  'phone': '493-170-9623 x156',\n",
       "  'website': 'kale.biz',\n",
       "  'company': {'name': 'Robel-Corkery',\n",
       "   'catchPhrase': 'Multi-tiered zero tolerance productivity',\n",
       "   'bs': 'transition cutting-edge web services'}},\n",
       " {'id': 5,\n",
       "  'name': 'Chelsey Dietrich',\n",
       "  'username': 'Kamren',\n",
       "  'email': 'Lucio_Hettinger@annie.ca',\n",
       "  'address': {'street': 'Skiles Walks',\n",
       "   'suite': 'Suite 351',\n",
       "   'city': 'Roscoeview',\n",
       "   'zipcode': '33263',\n",
       "   'geo': {'lat': '-31.8129', 'lng': '62.5342'}},\n",
       "  'phone': '(254)954-1289',\n",
       "  'website': 'demarco.info',\n",
       "  'company': {'name': 'Keebler LLC',\n",
       "   'catchPhrase': 'User-centric fault-tolerant solution',\n",
       "   'bs': 'revolutionize end-to-end systems'}},\n",
       " {'id': 6,\n",
       "  'name': 'Mrs. Dennis Schulist',\n",
       "  'username': 'Leopoldo_Corkery',\n",
       "  'email': 'Karley_Dach@jasper.info',\n",
       "  'address': {'street': 'Norberto Crossing',\n",
       "   'suite': 'Apt. 950',\n",
       "   'city': 'South Christy',\n",
       "   'zipcode': '23505-1337',\n",
       "   'geo': {'lat': '-71.4197', 'lng': '71.7478'}},\n",
       "  'phone': '1-477-935-8478 x6430',\n",
       "  'website': 'ola.org',\n",
       "  'company': {'name': 'Considine-Lockman',\n",
       "   'catchPhrase': 'Synchronised bottom-line interface',\n",
       "   'bs': 'e-enable innovative applications'}},\n",
       " {'id': 7,\n",
       "  'name': 'Kurtis Weissnat',\n",
       "  'username': 'Elwyn.Skiles',\n",
       "  'email': 'Telly.Hoeger@billy.biz',\n",
       "  'address': {'street': 'Rex Trail',\n",
       "   'suite': 'Suite 280',\n",
       "   'city': 'Howemouth',\n",
       "   'zipcode': '58804-1099',\n",
       "   'geo': {'lat': '24.8918', 'lng': '21.8984'}},\n",
       "  'phone': '210.067.6132',\n",
       "  'website': 'elvis.io',\n",
       "  'company': {'name': 'Johns Group',\n",
       "   'catchPhrase': 'Configurable multimedia task-force',\n",
       "   'bs': 'generate enterprise e-tailers'}},\n",
       " {'id': 8,\n",
       "  'name': 'Nicholas Runolfsdottir V',\n",
       "  'username': 'Maxime_Nienow',\n",
       "  'email': 'Sherwood@rosamond.me',\n",
       "  'address': {'street': 'Ellsworth Summit',\n",
       "   'suite': 'Suite 729',\n",
       "   'city': 'Aliyaview',\n",
       "   'zipcode': '45169',\n",
       "   'geo': {'lat': '-14.3990', 'lng': '-120.7677'}},\n",
       "  'phone': '586.493.6943 x140',\n",
       "  'website': 'jacynthe.com',\n",
       "  'company': {'name': 'Abernathy Group',\n",
       "   'catchPhrase': 'Implemented secondary concept',\n",
       "   'bs': 'e-enable extensible e-tailers'}},\n",
       " {'id': 9,\n",
       "  'name': 'Glenna Reichert',\n",
       "  'username': 'Delphine',\n",
       "  'email': 'Chaim_McDermott@dana.io',\n",
       "  'address': {'street': 'Dayna Park',\n",
       "   'suite': 'Suite 449',\n",
       "   'city': 'Bartholomebury',\n",
       "   'zipcode': '76495-3109',\n",
       "   'geo': {'lat': '24.6463', 'lng': '-168.8889'}},\n",
       "  'phone': '(775)976-6794 x41206',\n",
       "  'website': 'conrad.com',\n",
       "  'company': {'name': 'Yost and Sons',\n",
       "   'catchPhrase': 'Switchable contextually-based project',\n",
       "   'bs': 'aggregate real-time technologies'}},\n",
       " {'id': 10,\n",
       "  'name': 'Clementina DuBuque',\n",
       "  'username': 'Moriah.Stanton',\n",
       "  'email': 'Rey.Padberg@karina.biz',\n",
       "  'address': {'street': 'Kattie Turnpike',\n",
       "   'suite': 'Suite 198',\n",
       "   'city': 'Lebsackbury',\n",
       "   'zipcode': '31428-2261',\n",
       "   'geo': {'lat': '-38.2386', 'lng': '57.2232'}},\n",
       "  'phone': '024-648-3804',\n",
       "  'website': 'ambrose.net',\n",
       "  'company': {'name': 'Hoeger LLC',\n",
       "   'catchPhrase': 'Centralized empowering task-force',\n",
       "   'bs': 'target end-to-end models'}}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_json = json.loads(users.text)\n",
    "users_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>username</th>\n",
       "      <th>email</th>\n",
       "      <th>phone</th>\n",
       "      <th>website</th>\n",
       "      <th>address.street</th>\n",
       "      <th>address.suite</th>\n",
       "      <th>address.city</th>\n",
       "      <th>address.zipcode</th>\n",
       "      <th>address.geo.lat</th>\n",
       "      <th>address.geo.lng</th>\n",
       "      <th>company.name</th>\n",
       "      <th>company.catchPhrase</th>\n",
       "      <th>company.bs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Leanne Graham</td>\n",
       "      <td>Bret</td>\n",
       "      <td>Sincere@april.biz</td>\n",
       "      <td>1-770-736-8031 x56442</td>\n",
       "      <td>hildegard.org</td>\n",
       "      <td>Kulas Light</td>\n",
       "      <td>Apt. 556</td>\n",
       "      <td>Gwenborough</td>\n",
       "      <td>92998-3874</td>\n",
       "      <td>-37.3159</td>\n",
       "      <td>81.1496</td>\n",
       "      <td>Romaguera-Crona</td>\n",
       "      <td>Multi-layered client-server neural-net</td>\n",
       "      <td>harness real-time e-markets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ervin Howell</td>\n",
       "      <td>Antonette</td>\n",
       "      <td>Shanna@melissa.tv</td>\n",
       "      <td>010-692-6593 x09125</td>\n",
       "      <td>anastasia.net</td>\n",
       "      <td>Victor Plains</td>\n",
       "      <td>Suite 879</td>\n",
       "      <td>Wisokyburgh</td>\n",
       "      <td>90566-7771</td>\n",
       "      <td>-43.9509</td>\n",
       "      <td>-34.4618</td>\n",
       "      <td>Deckow-Crist</td>\n",
       "      <td>Proactive didactic contingency</td>\n",
       "      <td>synergize scalable supply-chains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Clementine Bauch</td>\n",
       "      <td>Samantha</td>\n",
       "      <td>Nathan@yesenia.net</td>\n",
       "      <td>1-463-123-4447</td>\n",
       "      <td>ramiro.info</td>\n",
       "      <td>Douglas Extension</td>\n",
       "      <td>Suite 847</td>\n",
       "      <td>McKenziehaven</td>\n",
       "      <td>59590-4157</td>\n",
       "      <td>-68.6102</td>\n",
       "      <td>-47.0653</td>\n",
       "      <td>Romaguera-Jacobson</td>\n",
       "      <td>Face to face bifurcated interface</td>\n",
       "      <td>e-enable strategic applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Patricia Lebsack</td>\n",
       "      <td>Karianne</td>\n",
       "      <td>Julianne.OConner@kory.org</td>\n",
       "      <td>493-170-9623 x156</td>\n",
       "      <td>kale.biz</td>\n",
       "      <td>Hoeger Mall</td>\n",
       "      <td>Apt. 692</td>\n",
       "      <td>South Elvis</td>\n",
       "      <td>53919-4257</td>\n",
       "      <td>29.4572</td>\n",
       "      <td>-164.2990</td>\n",
       "      <td>Robel-Corkery</td>\n",
       "      <td>Multi-tiered zero tolerance productivity</td>\n",
       "      <td>transition cutting-edge web services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Chelsey Dietrich</td>\n",
       "      <td>Kamren</td>\n",
       "      <td>Lucio_Hettinger@annie.ca</td>\n",
       "      <td>(254)954-1289</td>\n",
       "      <td>demarco.info</td>\n",
       "      <td>Skiles Walks</td>\n",
       "      <td>Suite 351</td>\n",
       "      <td>Roscoeview</td>\n",
       "      <td>33263</td>\n",
       "      <td>-31.8129</td>\n",
       "      <td>62.5342</td>\n",
       "      <td>Keebler LLC</td>\n",
       "      <td>User-centric fault-tolerant solution</td>\n",
       "      <td>revolutionize end-to-end systems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Mrs. Dennis Schulist</td>\n",
       "      <td>Leopoldo_Corkery</td>\n",
       "      <td>Karley_Dach@jasper.info</td>\n",
       "      <td>1-477-935-8478 x6430</td>\n",
       "      <td>ola.org</td>\n",
       "      <td>Norberto Crossing</td>\n",
       "      <td>Apt. 950</td>\n",
       "      <td>South Christy</td>\n",
       "      <td>23505-1337</td>\n",
       "      <td>-71.4197</td>\n",
       "      <td>71.7478</td>\n",
       "      <td>Considine-Lockman</td>\n",
       "      <td>Synchronised bottom-line interface</td>\n",
       "      <td>e-enable innovative applications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Kurtis Weissnat</td>\n",
       "      <td>Elwyn.Skiles</td>\n",
       "      <td>Telly.Hoeger@billy.biz</td>\n",
       "      <td>210.067.6132</td>\n",
       "      <td>elvis.io</td>\n",
       "      <td>Rex Trail</td>\n",
       "      <td>Suite 280</td>\n",
       "      <td>Howemouth</td>\n",
       "      <td>58804-1099</td>\n",
       "      <td>24.8918</td>\n",
       "      <td>21.8984</td>\n",
       "      <td>Johns Group</td>\n",
       "      <td>Configurable multimedia task-force</td>\n",
       "      <td>generate enterprise e-tailers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Nicholas Runolfsdottir V</td>\n",
       "      <td>Maxime_Nienow</td>\n",
       "      <td>Sherwood@rosamond.me</td>\n",
       "      <td>586.493.6943 x140</td>\n",
       "      <td>jacynthe.com</td>\n",
       "      <td>Ellsworth Summit</td>\n",
       "      <td>Suite 729</td>\n",
       "      <td>Aliyaview</td>\n",
       "      <td>45169</td>\n",
       "      <td>-14.3990</td>\n",
       "      <td>-120.7677</td>\n",
       "      <td>Abernathy Group</td>\n",
       "      <td>Implemented secondary concept</td>\n",
       "      <td>e-enable extensible e-tailers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Glenna Reichert</td>\n",
       "      <td>Delphine</td>\n",
       "      <td>Chaim_McDermott@dana.io</td>\n",
       "      <td>(775)976-6794 x41206</td>\n",
       "      <td>conrad.com</td>\n",
       "      <td>Dayna Park</td>\n",
       "      <td>Suite 449</td>\n",
       "      <td>Bartholomebury</td>\n",
       "      <td>76495-3109</td>\n",
       "      <td>24.6463</td>\n",
       "      <td>-168.8889</td>\n",
       "      <td>Yost and Sons</td>\n",
       "      <td>Switchable contextually-based project</td>\n",
       "      <td>aggregate real-time technologies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Clementina DuBuque</td>\n",
       "      <td>Moriah.Stanton</td>\n",
       "      <td>Rey.Padberg@karina.biz</td>\n",
       "      <td>024-648-3804</td>\n",
       "      <td>ambrose.net</td>\n",
       "      <td>Kattie Turnpike</td>\n",
       "      <td>Suite 198</td>\n",
       "      <td>Lebsackbury</td>\n",
       "      <td>31428-2261</td>\n",
       "      <td>-38.2386</td>\n",
       "      <td>57.2232</td>\n",
       "      <td>Hoeger LLC</td>\n",
       "      <td>Centralized empowering task-force</td>\n",
       "      <td>target end-to-end models</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                      name          username                      email  \\\n",
       "0   1             Leanne Graham              Bret          Sincere@april.biz   \n",
       "1   2              Ervin Howell         Antonette          Shanna@melissa.tv   \n",
       "2   3          Clementine Bauch          Samantha         Nathan@yesenia.net   \n",
       "3   4          Patricia Lebsack          Karianne  Julianne.OConner@kory.org   \n",
       "4   5          Chelsey Dietrich            Kamren   Lucio_Hettinger@annie.ca   \n",
       "5   6      Mrs. Dennis Schulist  Leopoldo_Corkery    Karley_Dach@jasper.info   \n",
       "6   7           Kurtis Weissnat      Elwyn.Skiles     Telly.Hoeger@billy.biz   \n",
       "7   8  Nicholas Runolfsdottir V     Maxime_Nienow       Sherwood@rosamond.me   \n",
       "8   9           Glenna Reichert          Delphine    Chaim_McDermott@dana.io   \n",
       "9  10        Clementina DuBuque    Moriah.Stanton     Rey.Padberg@karina.biz   \n",
       "\n",
       "                   phone        website     address.street address.suite  \\\n",
       "0  1-770-736-8031 x56442  hildegard.org        Kulas Light      Apt. 556   \n",
       "1    010-692-6593 x09125  anastasia.net      Victor Plains     Suite 879   \n",
       "2         1-463-123-4447    ramiro.info  Douglas Extension     Suite 847   \n",
       "3      493-170-9623 x156       kale.biz        Hoeger Mall      Apt. 692   \n",
       "4          (254)954-1289   demarco.info       Skiles Walks     Suite 351   \n",
       "5   1-477-935-8478 x6430        ola.org  Norberto Crossing      Apt. 950   \n",
       "6           210.067.6132       elvis.io          Rex Trail     Suite 280   \n",
       "7      586.493.6943 x140   jacynthe.com   Ellsworth Summit     Suite 729   \n",
       "8   (775)976-6794 x41206     conrad.com         Dayna Park     Suite 449   \n",
       "9           024-648-3804    ambrose.net    Kattie Turnpike     Suite 198   \n",
       "\n",
       "     address.city address.zipcode address.geo.lat address.geo.lng  \\\n",
       "0     Gwenborough      92998-3874        -37.3159         81.1496   \n",
       "1     Wisokyburgh      90566-7771        -43.9509        -34.4618   \n",
       "2   McKenziehaven      59590-4157        -68.6102        -47.0653   \n",
       "3     South Elvis      53919-4257         29.4572       -164.2990   \n",
       "4      Roscoeview           33263        -31.8129         62.5342   \n",
       "5   South Christy      23505-1337        -71.4197         71.7478   \n",
       "6       Howemouth      58804-1099         24.8918         21.8984   \n",
       "7       Aliyaview           45169        -14.3990       -120.7677   \n",
       "8  Bartholomebury      76495-3109         24.6463       -168.8889   \n",
       "9     Lebsackbury      31428-2261        -38.2386         57.2232   \n",
       "\n",
       "         company.name                       company.catchPhrase  \\\n",
       "0     Romaguera-Crona    Multi-layered client-server neural-net   \n",
       "1        Deckow-Crist            Proactive didactic contingency   \n",
       "2  Romaguera-Jacobson         Face to face bifurcated interface   \n",
       "3       Robel-Corkery  Multi-tiered zero tolerance productivity   \n",
       "4         Keebler LLC      User-centric fault-tolerant solution   \n",
       "5   Considine-Lockman        Synchronised bottom-line interface   \n",
       "6         Johns Group        Configurable multimedia task-force   \n",
       "7     Abernathy Group             Implemented secondary concept   \n",
       "8       Yost and Sons     Switchable contextually-based project   \n",
       "9          Hoeger LLC         Centralized empowering task-force   \n",
       "\n",
       "                             company.bs  \n",
       "0           harness real-time e-markets  \n",
       "1      synergize scalable supply-chains  \n",
       "2       e-enable strategic applications  \n",
       "3  transition cutting-edge web services  \n",
       "4      revolutionize end-to-end systems  \n",
       "5      e-enable innovative applications  \n",
       "6         generate enterprise e-tailers  \n",
       "7         e-enable extensible e-tailers  \n",
       "8      aggregate real-time technologies  \n",
       "9              target end-to-end models  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df = pd.json_normalize(users_json)\n",
    "users_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Situation 3: Metadata\n",
    "\n",
    "Finally, if the JSON file contains metadata (regardless of whether or not the records contain nested data), follow these steps:\n",
    "\n",
    "1. Use `requests.get()` to download the raw JSON data (unless you have another way of acquiring the raw data)\n",
    "\n",
    "2. Use `json.loads()` on the `.text` attribute of the output from step 1 to register the data as a list in Python\n",
    "\n",
    "3. Look at the data using a web-browser, or using the text that appears when the JSON object is called in Python, to decide on the path that is necessary to find the records\n",
    "\n",
    "4. Use the `pd.json_normalize()` function on the list that is the output of step 2. But within this function, use the `record_path` parameter and set it equal to a list with the keys, in order, that lead to the record\n",
    "\n",
    "5. Optionally, use the `meta` and `meta_prefix` parameters in `pd.json_normalize()` to store the metadata in the dataframe\n",
    "\n",
    "For example, we can access a JSON file for the top 25 top posts at the moment on [Reddit's r/popular page](https://www.reddit.com/r/popular/) here: http://www.reddit.com/r/popular/top.json. If our goal is to construct a data frame with 25 rows, one for each post, we must find the path that leads to these data. Looking at the web-browser, the top-level has two keys: \"kind\" and \"data\". \"kind\" is simply metadata telling us that this file contains listings, and the data live in \"data\". Within this branch, there are four more metadata branches, \"modhash\", \"dist\", \"before\", and \"after\", and the data we need exist within \"children\". So the path we need is `[\"data\", \"children\"]`. The code to construct the data frame we need is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>data.approved_at_utc</th>\n",
       "      <th>data.subreddit</th>\n",
       "      <th>data.selftext</th>\n",
       "      <th>data.author_fullname</th>\n",
       "      <th>data.saved</th>\n",
       "      <th>data.mod_reason_title</th>\n",
       "      <th>data.gilded</th>\n",
       "      <th>data.clicked</th>\n",
       "      <th>data.title</th>\n",
       "      <th>...</th>\n",
       "      <th>data.media.oembed.author_name</th>\n",
       "      <th>data.media.oembed.height</th>\n",
       "      <th>data.media.oembed.width</th>\n",
       "      <th>data.media.oembed.html</th>\n",
       "      <th>data.media.oembed.thumbnail_width</th>\n",
       "      <th>data.media.oembed.version</th>\n",
       "      <th>data.media.oembed.provider_name</th>\n",
       "      <th>data.media.oembed.thumbnail_url</th>\n",
       "      <th>data.media.oembed.thumbnail_height</th>\n",
       "      <th>data.link_flair_template_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>KidsAreFuckingStupid</td>\n",
       "      <td></td>\n",
       "      <td>t2_jkwyx</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>My girl does a 50 meter run-up to kick a ball</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td></td>\n",
       "      <td>t2_v51f9</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>TIL a Georgia teacher who bought a $400 travel...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>pics</td>\n",
       "      <td></td>\n",
       "      <td>t2_3nkxnuz0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>My painting today, â€œFaith and Fateâ€. Done with...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>memes</td>\n",
       "      <td></td>\n",
       "      <td>t2_47y2qd1c</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Sully boi</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>mildlyinteresting</td>\n",
       "      <td></td>\n",
       "      <td>t2_9zcsxqk</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Our neighbors pet pig stays on their porch all...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>aww</td>\n",
       "      <td></td>\n",
       "      <td>t2_15d4m3</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>We adopted a senior doggo and he loves sleepin...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>nextfuckinglevel</td>\n",
       "      <td></td>\n",
       "      <td>t2_xduj3</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Ref saves fighters head from hitting floor</td>\n",
       "      <td>...</td>\n",
       "      <td>Gfycat</td>\n",
       "      <td>337.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>&amp;lt;iframe class=\"embedly-embed\" src=\"https://...</td>\n",
       "      <td>444.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Gfycat</td>\n",
       "      <td>https://thumbs.gfycat.com/FastValidBlackfish-s...</td>\n",
       "      <td>250.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>funny</td>\n",
       "      <td></td>\n",
       "      <td>t2_6fpnv</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Mother-in-law just served me this piece of cak...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>aww</td>\n",
       "      <td></td>\n",
       "      <td>t2_ayyx6</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Ocelot scratches!</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>funny</td>\n",
       "      <td></td>\n",
       "      <td>t2_4cf674sy</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Wiener of Shame!</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>nextfuckinglevel</td>\n",
       "      <td></td>\n",
       "      <td>t2_3dtthbpp</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>I love watching talent progression!</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>memes</td>\n",
       "      <td></td>\n",
       "      <td>t2_4dyr5fo8</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>Do not suggest anything to your boss in a boar...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>interestingasfuck</td>\n",
       "      <td></td>\n",
       "      <td>t2_ar7lvxr</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Divers walking upside-down underneath ice</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td></td>\n",
       "      <td>t2_5e7f3bem</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>Doctors of Reddit, what's the biggest case of ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>therewasanattempt</td>\n",
       "      <td></td>\n",
       "      <td>t2_r1i19</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>to protect and serve</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>MadeMeSmile</td>\n",
       "      <td></td>\n",
       "      <td>t2_16qd6g</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>I'm a lone dad that's shaved my head all my li...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>wholesomememes</td>\n",
       "      <td></td>\n",
       "      <td>t2_344uuir9</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank you mom</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td></td>\n",
       "      <td>t2_17am3d</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>$2.97 Headphone stand</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6bd464aa-c51a-11e3-85ad-12313d163aa0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>WatchPeopleDieInside</td>\n",
       "      <td></td>\n",
       "      <td>t2_1jtr3unj</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Realizing you're about to be guarded by a 7'4\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>aww</td>\n",
       "      <td></td>\n",
       "      <td>t2_552sq4vz</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Bath time</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>comics</td>\n",
       "      <td></td>\n",
       "      <td>t2_4jkot8yv</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>[OC] ..dog world problems</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>gifs</td>\n",
       "      <td></td>\n",
       "      <td>t2_ayyx6</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Child is endlessly amused by kissing an orangu...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>oddlysatisfying</td>\n",
       "      <td></td>\n",
       "      <td>t2_3zdo30sv</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Picture of the Sky from a plane</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>aww</td>\n",
       "      <td></td>\n",
       "      <td>t2_8w94q</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Synchronized wagging</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>HolUp</td>\n",
       "      <td></td>\n",
       "      <td>t2_3msic3xp</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>hol the fuck up</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows Ã— 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   kind data.approved_at_utc        data.subreddit data.selftext  \\\n",
       "0    t3                 None  KidsAreFuckingStupid                 \n",
       "1    t3                 None         todayilearned                 \n",
       "2    t3                 None                  pics                 \n",
       "3    t3                 None                 memes                 \n",
       "4    t3                 None     mildlyinteresting                 \n",
       "5    t3                 None                   aww                 \n",
       "6    t3                 None      nextfuckinglevel                 \n",
       "7    t3                 None                 funny                 \n",
       "8    t3                 None                   aww                 \n",
       "9    t3                 None                 funny                 \n",
       "10   t3                 None      nextfuckinglevel                 \n",
       "11   t3                 None                 memes                 \n",
       "12   t3                 None     interestingasfuck                 \n",
       "13   t3                 None             AskReddit                 \n",
       "14   t3                 None     therewasanattempt                 \n",
       "15   t3                 None           MadeMeSmile                 \n",
       "16   t3                 None        wholesomememes                 \n",
       "17   t3                 None          pcmasterrace                 \n",
       "18   t3                 None  WatchPeopleDieInside                 \n",
       "19   t3                 None                   aww                 \n",
       "20   t3                 None                comics                 \n",
       "21   t3                 None                  gifs                 \n",
       "22   t3                 None       oddlysatisfying                 \n",
       "23   t3                 None                   aww                 \n",
       "24   t3                 None                 HolUp                 \n",
       "\n",
       "   data.author_fullname  data.saved data.mod_reason_title  data.gilded  \\\n",
       "0              t2_jkwyx       False                  None            1   \n",
       "1              t2_v51f9       False                  None            2   \n",
       "2           t2_3nkxnuz0       False                  None            7   \n",
       "3           t2_47y2qd1c       False                  None            0   \n",
       "4            t2_9zcsxqk       False                  None            0   \n",
       "5             t2_15d4m3       False                  None            2   \n",
       "6              t2_xduj3       False                  None            1   \n",
       "7              t2_6fpnv       False                  None            0   \n",
       "8              t2_ayyx6       False                  None            1   \n",
       "9           t2_4cf674sy       False                  None            1   \n",
       "10          t2_3dtthbpp       False                  None            3   \n",
       "11          t2_4dyr5fo8       False                  None            3   \n",
       "12           t2_ar7lvxr       False                  None            0   \n",
       "13          t2_5e7f3bem       False                  None            4   \n",
       "14             t2_r1i19       False                  None            1   \n",
       "15            t2_16qd6g       False                  None            5   \n",
       "16          t2_344uuir9       False                  None            0   \n",
       "17            t2_17am3d       False                  None            1   \n",
       "18          t2_1jtr3unj       False                  None            0   \n",
       "19          t2_552sq4vz       False                  None            0   \n",
       "20          t2_4jkot8yv       False                  None            3   \n",
       "21             t2_ayyx6       False                  None            1   \n",
       "22          t2_3zdo30sv       False                  None            1   \n",
       "23             t2_8w94q       False                  None            0   \n",
       "24          t2_3msic3xp       False                  None            0   \n",
       "\n",
       "    data.clicked                                         data.title  ...  \\\n",
       "0          False      My girl does a 50 meter run-up to kick a ball  ...   \n",
       "1          False  TIL a Georgia teacher who bought a $400 travel...  ...   \n",
       "2          False  My painting today, â€œFaith and Fateâ€. Done with...  ...   \n",
       "3          False                                          Sully boi  ...   \n",
       "4          False  Our neighbors pet pig stays on their porch all...  ...   \n",
       "5          False  We adopted a senior doggo and he loves sleepin...  ...   \n",
       "6          False         Ref saves fighters head from hitting floor  ...   \n",
       "7          False  Mother-in-law just served me this piece of cak...  ...   \n",
       "8          False                                  Ocelot scratches!  ...   \n",
       "9          False                                   Wiener of Shame!  ...   \n",
       "10         False                I love watching talent progression!  ...   \n",
       "11         False  Do not suggest anything to your boss in a boar...  ...   \n",
       "12         False          Divers walking upside-down underneath ice  ...   \n",
       "13         False  Doctors of Reddit, what's the biggest case of ...  ...   \n",
       "14         False                               to protect and serve  ...   \n",
       "15         False  I'm a lone dad that's shaved my head all my li...  ...   \n",
       "16         False                                      Thank you mom  ...   \n",
       "17         False                              $2.97 Headphone stand  ...   \n",
       "18         False  Realizing you're about to be guarded by a 7'4\"...  ...   \n",
       "19         False                                          Bath time  ...   \n",
       "20         False                          [OC] ..dog world problems  ...   \n",
       "21         False  Child is endlessly amused by kissing an orangu...  ...   \n",
       "22         False                    Picture of the Sky from a plane  ...   \n",
       "23         False                               Synchronized wagging  ...   \n",
       "24         False                                    hol the fuck up  ...   \n",
       "\n",
       "   data.media.oembed.author_name data.media.oembed.height  \\\n",
       "0                            NaN                      NaN   \n",
       "1                            NaN                      NaN   \n",
       "2                            NaN                      NaN   \n",
       "3                            NaN                      NaN   \n",
       "4                            NaN                      NaN   \n",
       "5                            NaN                      NaN   \n",
       "6                         Gfycat                    337.0   \n",
       "7                            NaN                      NaN   \n",
       "8                            NaN                      NaN   \n",
       "9                            NaN                      NaN   \n",
       "10                           NaN                      NaN   \n",
       "11                           NaN                      NaN   \n",
       "12                           NaN                      NaN   \n",
       "13                           NaN                      NaN   \n",
       "14                           NaN                      NaN   \n",
       "15                           NaN                      NaN   \n",
       "16                           NaN                      NaN   \n",
       "17                           NaN                      NaN   \n",
       "18                           NaN                      NaN   \n",
       "19                           NaN                      NaN   \n",
       "20                           NaN                      NaN   \n",
       "21                           NaN                      NaN   \n",
       "22                           NaN                      NaN   \n",
       "23                           NaN                      NaN   \n",
       "24                           NaN                      NaN   \n",
       "\n",
       "    data.media.oembed.width  \\\n",
       "0                       NaN   \n",
       "1                       NaN   \n",
       "2                       NaN   \n",
       "3                       NaN   \n",
       "4                       NaN   \n",
       "5                       NaN   \n",
       "6                     600.0   \n",
       "7                       NaN   \n",
       "8                       NaN   \n",
       "9                       NaN   \n",
       "10                      NaN   \n",
       "11                      NaN   \n",
       "12                      NaN   \n",
       "13                      NaN   \n",
       "14                      NaN   \n",
       "15                      NaN   \n",
       "16                      NaN   \n",
       "17                      NaN   \n",
       "18                      NaN   \n",
       "19                      NaN   \n",
       "20                      NaN   \n",
       "21                      NaN   \n",
       "22                      NaN   \n",
       "23                      NaN   \n",
       "24                      NaN   \n",
       "\n",
       "                               data.media.oembed.html  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6   &lt;iframe class=\"embedly-embed\" src=\"https://...   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "\n",
       "   data.media.oembed.thumbnail_width  data.media.oembed.version  \\\n",
       "0                                NaN                        NaN   \n",
       "1                                NaN                        NaN   \n",
       "2                                NaN                        NaN   \n",
       "3                                NaN                        NaN   \n",
       "4                                NaN                        NaN   \n",
       "5                                NaN                        NaN   \n",
       "6                              444.0                        1.0   \n",
       "7                                NaN                        NaN   \n",
       "8                                NaN                        NaN   \n",
       "9                                NaN                        NaN   \n",
       "10                               NaN                        NaN   \n",
       "11                               NaN                        NaN   \n",
       "12                               NaN                        NaN   \n",
       "13                               NaN                        NaN   \n",
       "14                               NaN                        NaN   \n",
       "15                               NaN                        NaN   \n",
       "16                               NaN                        NaN   \n",
       "17                               NaN                        NaN   \n",
       "18                               NaN                        NaN   \n",
       "19                               NaN                        NaN   \n",
       "20                               NaN                        NaN   \n",
       "21                               NaN                        NaN   \n",
       "22                               NaN                        NaN   \n",
       "23                               NaN                        NaN   \n",
       "24                               NaN                        NaN   \n",
       "\n",
       "    data.media.oembed.provider_name  \\\n",
       "0                               NaN   \n",
       "1                               NaN   \n",
       "2                               NaN   \n",
       "3                               NaN   \n",
       "4                               NaN   \n",
       "5                               NaN   \n",
       "6                            Gfycat   \n",
       "7                               NaN   \n",
       "8                               NaN   \n",
       "9                               NaN   \n",
       "10                              NaN   \n",
       "11                              NaN   \n",
       "12                              NaN   \n",
       "13                              NaN   \n",
       "14                              NaN   \n",
       "15                              NaN   \n",
       "16                              NaN   \n",
       "17                              NaN   \n",
       "18                              NaN   \n",
       "19                              NaN   \n",
       "20                              NaN   \n",
       "21                              NaN   \n",
       "22                              NaN   \n",
       "23                              NaN   \n",
       "24                              NaN   \n",
       "\n",
       "                      data.media.oembed.thumbnail_url  \\\n",
       "0                                                 NaN   \n",
       "1                                                 NaN   \n",
       "2                                                 NaN   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5                                                 NaN   \n",
       "6   https://thumbs.gfycat.com/FastValidBlackfish-s...   \n",
       "7                                                 NaN   \n",
       "8                                                 NaN   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16                                                NaN   \n",
       "17                                                NaN   \n",
       "18                                                NaN   \n",
       "19                                                NaN   \n",
       "20                                                NaN   \n",
       "21                                                NaN   \n",
       "22                                                NaN   \n",
       "23                                                NaN   \n",
       "24                                                NaN   \n",
       "\n",
       "   data.media.oembed.thumbnail_height           data.link_flair_template_id  \n",
       "0                                 NaN                                   NaN  \n",
       "1                                 NaN                                   NaN  \n",
       "2                                 NaN                                   NaN  \n",
       "3                                 NaN                                   NaN  \n",
       "4                                 NaN                                   NaN  \n",
       "5                                 NaN                                   NaN  \n",
       "6                               250.0                                   NaN  \n",
       "7                                 NaN                                   NaN  \n",
       "8                                 NaN                                   NaN  \n",
       "9                                 NaN                                   NaN  \n",
       "10                                NaN                                   NaN  \n",
       "11                                NaN                                   NaN  \n",
       "12                                NaN                                   NaN  \n",
       "13                                NaN                                   NaN  \n",
       "14                                NaN                                   NaN  \n",
       "15                                NaN                                   NaN  \n",
       "16                                NaN                                   NaN  \n",
       "17                                NaN  6bd464aa-c51a-11e3-85ad-12313d163aa0  \n",
       "18                                NaN                                   NaN  \n",
       "19                                NaN                                   NaN  \n",
       "20                                NaN                                   NaN  \n",
       "21                                NaN                                   NaN  \n",
       "22                                NaN                                   NaN  \n",
       "23                                NaN                                   NaN  \n",
       "24                                NaN                                   NaN  \n",
       "\n",
       "[25 rows x 170 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://www.reddit.com/r/popular/top.json\"\n",
    "reddit = requests.get(url, headers = {'User-agent': 'DS6001'})\n",
    "reddit_json = json.loads(reddit.text)\n",
    "reddit_df = pd.json_normalize(reddit_json, record_path = [\"data\", \"children\"])\n",
    "reddit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note: we added `headers = {'User-agent': 'DS6001'}` to the `requests.get()` function. When we use `requests.get()`, we are accessing an API: a web-based interface for transferring data, usually in the form of JSON files. We will cover APIs in the next module. Most APIs, including Reddit's, include some security to keep any one user from overusing the API and causing it to crash. For Reddit, we only need to provide a unique \"[User-agent](https://www.reddit.com/r/redditdev/comments/3qbll8/429_too_many_requests/)\", which is an ID that Reddit uses to keep track of how much we are using the API. If two people use the same User-agent, both uses are counted against the same limit, so it's better to choose a User-agent that has a unique name. If this block of code results in an error for you (so that `reddit.text` displays as `'{\"message\": \"Too Many Requests\", \"error\": 429}'`), then change `DS6001` to something else, and it should work. \n",
    "\n",
    "To save the metadata in the data frame, use the `meta` parameter, set equal to a list of paths for each metadata feature you wish to store in the dataframe. In this case, to save the \"kind\" feature and the \"after\" feature within the \"data\" branch, I type `meta = ['kind', ['data', 'after']]`. Finally, because there is already a `kind` feature stored within the records, I must distinguish the metadata feature with a prefix. I use `meta_prefix='meta'` to place \"meta\" prior to the column names of the metadata.\n",
    "\n",
    "Because metadata exist outside of the records, they will be constant across the rows in the dataframe. Here's the code to convert the Reddit data to a data frame while storing the metadata. Take a look at the resulting dataframe and scroll all the way to the right to see the two metadata columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>data.approved_at_utc</th>\n",
       "      <th>data.subreddit</th>\n",
       "      <th>data.selftext</th>\n",
       "      <th>data.author_fullname</th>\n",
       "      <th>data.saved</th>\n",
       "      <th>data.mod_reason_title</th>\n",
       "      <th>data.gilded</th>\n",
       "      <th>data.clicked</th>\n",
       "      <th>data.title</th>\n",
       "      <th>...</th>\n",
       "      <th>data.media.oembed.thumbnail_width</th>\n",
       "      <th>data.media.oembed.version</th>\n",
       "      <th>data.media.oembed.provider_name</th>\n",
       "      <th>data.media.oembed.thumbnail_url</th>\n",
       "      <th>data.media.oembed.type</th>\n",
       "      <th>data.media.oembed.thumbnail_height</th>\n",
       "      <th>data.media.type</th>\n",
       "      <th>data.link_flair_template_id</th>\n",
       "      <th>metakind</th>\n",
       "      <th>metadata.after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>KidsAreFuckingStupid</td>\n",
       "      <td></td>\n",
       "      <td>t2_jkwyx</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>My girl does a 50 meter run-up to kick a ball</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td></td>\n",
       "      <td>t2_v51f9</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>TIL a Georgia teacher who bought a $400 travel...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>pics</td>\n",
       "      <td></td>\n",
       "      <td>t2_3nkxnuz0</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>My painting today, â€œFaith and Fateâ€. Done with...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>memes</td>\n",
       "      <td></td>\n",
       "      <td>t2_47y2qd1c</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Sully boi</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>mildlyinteresting</td>\n",
       "      <td></td>\n",
       "      <td>t2_9zcsxqk</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Our neighbors pet pig stays on their porch all...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>aww</td>\n",
       "      <td></td>\n",
       "      <td>t2_15d4m3</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>We adopted a senior doggo and he loves sleepin...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>nextfuckinglevel</td>\n",
       "      <td></td>\n",
       "      <td>t2_xduj3</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Ref saves fighters head from hitting floor</td>\n",
       "      <td>...</td>\n",
       "      <td>444.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Gfycat</td>\n",
       "      <td>https://thumbs.gfycat.com/FastValidBlackfish-s...</td>\n",
       "      <td>video</td>\n",
       "      <td>250.0</td>\n",
       "      <td>gfycat.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>funny</td>\n",
       "      <td></td>\n",
       "      <td>t2_6fpnv</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Mother-in-law just served me this piece of cak...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>aww</td>\n",
       "      <td></td>\n",
       "      <td>t2_ayyx6</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Ocelot scratches!</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>funny</td>\n",
       "      <td></td>\n",
       "      <td>t2_4cf674sy</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Wiener of Shame!</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>nextfuckinglevel</td>\n",
       "      <td></td>\n",
       "      <td>t2_3dtthbpp</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>I love watching talent progression!</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>memes</td>\n",
       "      <td></td>\n",
       "      <td>t2_4dyr5fo8</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>Do not suggest anything to your boss in a boar...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>interestingasfuck</td>\n",
       "      <td></td>\n",
       "      <td>t2_ar7lvxr</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Divers walking upside-down underneath ice</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td></td>\n",
       "      <td>t2_5e7f3bem</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>Doctors of Reddit, what's the biggest case of ...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>therewasanattempt</td>\n",
       "      <td></td>\n",
       "      <td>t2_r1i19</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>to protect and serve</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>MadeMeSmile</td>\n",
       "      <td></td>\n",
       "      <td>t2_16qd6g</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>I'm a lone dad that's shaved my head all my li...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>wholesomememes</td>\n",
       "      <td></td>\n",
       "      <td>t2_344uuir9</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank you mom</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>pcmasterrace</td>\n",
       "      <td></td>\n",
       "      <td>t2_17am3d</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>$2.97 Headphone stand</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6bd464aa-c51a-11e3-85ad-12313d163aa0</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>WatchPeopleDieInside</td>\n",
       "      <td></td>\n",
       "      <td>t2_1jtr3unj</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Realizing you're about to be guarded by a 7'4\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>aww</td>\n",
       "      <td></td>\n",
       "      <td>t2_552sq4vz</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Bath time</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>comics</td>\n",
       "      <td></td>\n",
       "      <td>t2_4jkot8yv</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>[OC] ..dog world problems</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>gifs</td>\n",
       "      <td></td>\n",
       "      <td>t2_ayyx6</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Child is endlessly amused by kissing an orangu...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>oddlysatisfying</td>\n",
       "      <td></td>\n",
       "      <td>t2_3zdo30sv</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Picture of the Sky from a plane</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>aww</td>\n",
       "      <td></td>\n",
       "      <td>t2_8w94q</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>Synchronized wagging</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "      <td>HolUp</td>\n",
       "      <td></td>\n",
       "      <td>t2_3msic3xp</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>hol the fuck up</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Listing</td>\n",
       "      <td>t3_f4t7mb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25 rows Ã— 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   kind data.approved_at_utc        data.subreddit data.selftext  \\\n",
       "0    t3                 None  KidsAreFuckingStupid                 \n",
       "1    t3                 None         todayilearned                 \n",
       "2    t3                 None                  pics                 \n",
       "3    t3                 None                 memes                 \n",
       "4    t3                 None     mildlyinteresting                 \n",
       "5    t3                 None                   aww                 \n",
       "6    t3                 None      nextfuckinglevel                 \n",
       "7    t3                 None                 funny                 \n",
       "8    t3                 None                   aww                 \n",
       "9    t3                 None                 funny                 \n",
       "10   t3                 None      nextfuckinglevel                 \n",
       "11   t3                 None                 memes                 \n",
       "12   t3                 None     interestingasfuck                 \n",
       "13   t3                 None             AskReddit                 \n",
       "14   t3                 None     therewasanattempt                 \n",
       "15   t3                 None           MadeMeSmile                 \n",
       "16   t3                 None        wholesomememes                 \n",
       "17   t3                 None          pcmasterrace                 \n",
       "18   t3                 None  WatchPeopleDieInside                 \n",
       "19   t3                 None                   aww                 \n",
       "20   t3                 None                comics                 \n",
       "21   t3                 None                  gifs                 \n",
       "22   t3                 None       oddlysatisfying                 \n",
       "23   t3                 None                   aww                 \n",
       "24   t3                 None                 HolUp                 \n",
       "\n",
       "   data.author_fullname  data.saved data.mod_reason_title  data.gilded  \\\n",
       "0              t2_jkwyx       False                  None            1   \n",
       "1              t2_v51f9       False                  None            2   \n",
       "2           t2_3nkxnuz0       False                  None            7   \n",
       "3           t2_47y2qd1c       False                  None            0   \n",
       "4            t2_9zcsxqk       False                  None            0   \n",
       "5             t2_15d4m3       False                  None            2   \n",
       "6              t2_xduj3       False                  None            1   \n",
       "7              t2_6fpnv       False                  None            0   \n",
       "8              t2_ayyx6       False                  None            1   \n",
       "9           t2_4cf674sy       False                  None            1   \n",
       "10          t2_3dtthbpp       False                  None            3   \n",
       "11          t2_4dyr5fo8       False                  None            3   \n",
       "12           t2_ar7lvxr       False                  None            0   \n",
       "13          t2_5e7f3bem       False                  None            4   \n",
       "14             t2_r1i19       False                  None            1   \n",
       "15            t2_16qd6g       False                  None            5   \n",
       "16          t2_344uuir9       False                  None            0   \n",
       "17            t2_17am3d       False                  None            1   \n",
       "18          t2_1jtr3unj       False                  None            0   \n",
       "19          t2_552sq4vz       False                  None            0   \n",
       "20          t2_4jkot8yv       False                  None            3   \n",
       "21             t2_ayyx6       False                  None            1   \n",
       "22          t2_3zdo30sv       False                  None            1   \n",
       "23             t2_8w94q       False                  None            0   \n",
       "24          t2_3msic3xp       False                  None            0   \n",
       "\n",
       "    data.clicked                                         data.title  ...  \\\n",
       "0          False      My girl does a 50 meter run-up to kick a ball  ...   \n",
       "1          False  TIL a Georgia teacher who bought a $400 travel...  ...   \n",
       "2          False  My painting today, â€œFaith and Fateâ€. Done with...  ...   \n",
       "3          False                                          Sully boi  ...   \n",
       "4          False  Our neighbors pet pig stays on their porch all...  ...   \n",
       "5          False  We adopted a senior doggo and he loves sleepin...  ...   \n",
       "6          False         Ref saves fighters head from hitting floor  ...   \n",
       "7          False  Mother-in-law just served me this piece of cak...  ...   \n",
       "8          False                                  Ocelot scratches!  ...   \n",
       "9          False                                   Wiener of Shame!  ...   \n",
       "10         False                I love watching talent progression!  ...   \n",
       "11         False  Do not suggest anything to your boss in a boar...  ...   \n",
       "12         False          Divers walking upside-down underneath ice  ...   \n",
       "13         False  Doctors of Reddit, what's the biggest case of ...  ...   \n",
       "14         False                               to protect and serve  ...   \n",
       "15         False  I'm a lone dad that's shaved my head all my li...  ...   \n",
       "16         False                                      Thank you mom  ...   \n",
       "17         False                              $2.97 Headphone stand  ...   \n",
       "18         False  Realizing you're about to be guarded by a 7'4\"...  ...   \n",
       "19         False                                          Bath time  ...   \n",
       "20         False                          [OC] ..dog world problems  ...   \n",
       "21         False  Child is endlessly amused by kissing an orangu...  ...   \n",
       "22         False                    Picture of the Sky from a plane  ...   \n",
       "23         False                               Synchronized wagging  ...   \n",
       "24         False                                    hol the fuck up  ...   \n",
       "\n",
       "   data.media.oembed.thumbnail_width data.media.oembed.version  \\\n",
       "0                                NaN                       NaN   \n",
       "1                                NaN                       NaN   \n",
       "2                                NaN                       NaN   \n",
       "3                                NaN                       NaN   \n",
       "4                                NaN                       NaN   \n",
       "5                                NaN                       NaN   \n",
       "6                              444.0                       1.0   \n",
       "7                                NaN                       NaN   \n",
       "8                                NaN                       NaN   \n",
       "9                                NaN                       NaN   \n",
       "10                               NaN                       NaN   \n",
       "11                               NaN                       NaN   \n",
       "12                               NaN                       NaN   \n",
       "13                               NaN                       NaN   \n",
       "14                               NaN                       NaN   \n",
       "15                               NaN                       NaN   \n",
       "16                               NaN                       NaN   \n",
       "17                               NaN                       NaN   \n",
       "18                               NaN                       NaN   \n",
       "19                               NaN                       NaN   \n",
       "20                               NaN                       NaN   \n",
       "21                               NaN                       NaN   \n",
       "22                               NaN                       NaN   \n",
       "23                               NaN                       NaN   \n",
       "24                               NaN                       NaN   \n",
       "\n",
       "    data.media.oembed.provider_name  \\\n",
       "0                               NaN   \n",
       "1                               NaN   \n",
       "2                               NaN   \n",
       "3                               NaN   \n",
       "4                               NaN   \n",
       "5                               NaN   \n",
       "6                            Gfycat   \n",
       "7                               NaN   \n",
       "8                               NaN   \n",
       "9                               NaN   \n",
       "10                              NaN   \n",
       "11                              NaN   \n",
       "12                              NaN   \n",
       "13                              NaN   \n",
       "14                              NaN   \n",
       "15                              NaN   \n",
       "16                              NaN   \n",
       "17                              NaN   \n",
       "18                              NaN   \n",
       "19                              NaN   \n",
       "20                              NaN   \n",
       "21                              NaN   \n",
       "22                              NaN   \n",
       "23                              NaN   \n",
       "24                              NaN   \n",
       "\n",
       "                      data.media.oembed.thumbnail_url data.media.oembed.type  \\\n",
       "0                                                 NaN                    NaN   \n",
       "1                                                 NaN                    NaN   \n",
       "2                                                 NaN                    NaN   \n",
       "3                                                 NaN                    NaN   \n",
       "4                                                 NaN                    NaN   \n",
       "5                                                 NaN                    NaN   \n",
       "6   https://thumbs.gfycat.com/FastValidBlackfish-s...                  video   \n",
       "7                                                 NaN                    NaN   \n",
       "8                                                 NaN                    NaN   \n",
       "9                                                 NaN                    NaN   \n",
       "10                                                NaN                    NaN   \n",
       "11                                                NaN                    NaN   \n",
       "12                                                NaN                    NaN   \n",
       "13                                                NaN                    NaN   \n",
       "14                                                NaN                    NaN   \n",
       "15                                                NaN                    NaN   \n",
       "16                                                NaN                    NaN   \n",
       "17                                                NaN                    NaN   \n",
       "18                                                NaN                    NaN   \n",
       "19                                                NaN                    NaN   \n",
       "20                                                NaN                    NaN   \n",
       "21                                                NaN                    NaN   \n",
       "22                                                NaN                    NaN   \n",
       "23                                                NaN                    NaN   \n",
       "24                                                NaN                    NaN   \n",
       "\n",
       "    data.media.oembed.thumbnail_height  data.media.type  \\\n",
       "0                                  NaN              NaN   \n",
       "1                                  NaN              NaN   \n",
       "2                                  NaN              NaN   \n",
       "3                                  NaN              NaN   \n",
       "4                                  NaN              NaN   \n",
       "5                                  NaN              NaN   \n",
       "6                                250.0       gfycat.com   \n",
       "7                                  NaN              NaN   \n",
       "8                                  NaN              NaN   \n",
       "9                                  NaN              NaN   \n",
       "10                                 NaN              NaN   \n",
       "11                                 NaN              NaN   \n",
       "12                                 NaN              NaN   \n",
       "13                                 NaN              NaN   \n",
       "14                                 NaN              NaN   \n",
       "15                                 NaN              NaN   \n",
       "16                                 NaN              NaN   \n",
       "17                                 NaN              NaN   \n",
       "18                                 NaN              NaN   \n",
       "19                                 NaN              NaN   \n",
       "20                                 NaN              NaN   \n",
       "21                                 NaN              NaN   \n",
       "22                                 NaN              NaN   \n",
       "23                                 NaN              NaN   \n",
       "24                                 NaN              NaN   \n",
       "\n",
       "             data.link_flair_template_id metakind  metadata.after  \n",
       "0                                    NaN  Listing       t3_f4t7mb  \n",
       "1                                    NaN  Listing       t3_f4t7mb  \n",
       "2                                    NaN  Listing       t3_f4t7mb  \n",
       "3                                    NaN  Listing       t3_f4t7mb  \n",
       "4                                    NaN  Listing       t3_f4t7mb  \n",
       "5                                    NaN  Listing       t3_f4t7mb  \n",
       "6                                    NaN  Listing       t3_f4t7mb  \n",
       "7                                    NaN  Listing       t3_f4t7mb  \n",
       "8                                    NaN  Listing       t3_f4t7mb  \n",
       "9                                    NaN  Listing       t3_f4t7mb  \n",
       "10                                   NaN  Listing       t3_f4t7mb  \n",
       "11                                   NaN  Listing       t3_f4t7mb  \n",
       "12                                   NaN  Listing       t3_f4t7mb  \n",
       "13                                   NaN  Listing       t3_f4t7mb  \n",
       "14                                   NaN  Listing       t3_f4t7mb  \n",
       "15                                   NaN  Listing       t3_f4t7mb  \n",
       "16                                   NaN  Listing       t3_f4t7mb  \n",
       "17  6bd464aa-c51a-11e3-85ad-12313d163aa0  Listing       t3_f4t7mb  \n",
       "18                                   NaN  Listing       t3_f4t7mb  \n",
       "19                                   NaN  Listing       t3_f4t7mb  \n",
       "20                                   NaN  Listing       t3_f4t7mb  \n",
       "21                                   NaN  Listing       t3_f4t7mb  \n",
       "22                                   NaN  Listing       t3_f4t7mb  \n",
       "23                                   NaN  Listing       t3_f4t7mb  \n",
       "24                                   NaN  Listing       t3_f4t7mb  \n",
       "\n",
       "[25 rows x 172 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://www.reddit.com/r/popular/top.json\"\n",
    "reddit = requests.get(url, headers = {'User-agent': 'DS6001'})\n",
    "reddit_json = json.loads(reddit.text)\n",
    "reddit_df = pd.json_normalize(reddit_json, \n",
    "                              record_path = [\"data\", \"children\"], \n",
    "                              meta = ['kind', ['data', 'after']], \n",
    "                              meta_prefix = \"meta\")\n",
    "reddit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving JSON Files and Converting Data Frames to JSON\n",
    "It is possible to save a JSON file to your local disk space, or to convert a dataframe to JSON and, if you want to, save that JSON to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Existing JSON Files to Disk\n",
    "Once we've used the `json.loads()` function to register data as JSON in Python, we can save that JSON to our local disk space by using `open()` to create a new file, and `json.dump()` (note: not `json.dumps()`) to save the JSON to that file.\n",
    "\n",
    "For example, we registered the customer data as JSON in Python with the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = requests.get(\"https://jsonplaceholder.typicode.com/users\")\n",
    "users_json = json.loads(users.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save this JSON file to my harddrive, I first use `os.chdir()` to set the working directory to the folder where I want to save my JSON file. (I omit that code here because it won't work on other people's computers.) Then I type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('users.json', 'w') as outfile:\n",
    "     json.dump(users_json, outfile, sort_keys = True, indent = 4,\n",
    "               ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to use a file extension such as `.txt` instead of `.json` to save the JSON formatted data in a plain text file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Tabular DataFrames to JSON\n",
    "Any dataframe can be turned into a JSON file by applying the `.to_json()` method to the dataframe that is saved in Python's memory. The trick is specifying a good organization for this file. Recall that JSON structures are much more flexible than dataframes. It is not possible to go from a dataframe to a nested, complicated JSON structure because the information about nesting simply does not exist for dataframes. That said, there are several choices for organizing the data:\n",
    "\n",
    "* `orient=\"records\"` works with JSON files organized as a list-of-sets, where each set is an entire record (or a row in flat data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'name': 'Leanne Graham',\n",
       " 'username': 'Bret',\n",
       " 'email': 'Sincere@april.biz',\n",
       " 'phone': '1-770-736-8031 x56442',\n",
       " 'website': 'hildegard.org',\n",
       " 'address.street': 'Kulas Light',\n",
       " 'address.suite': 'Apt. 556',\n",
       " 'address.city': 'Gwenborough',\n",
       " 'address.zipcode': '92998-3874',\n",
       " 'address.geo.lat': '-37.3159',\n",
       " 'address.geo.lng': '81.1496',\n",
       " 'company.name': 'Romaguera-Crona',\n",
       " 'company.catchPhrase': 'Multi-layered client-server neural-net',\n",
       " 'company.bs': 'harness real-time e-markets'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_df = users_df.loc[0:2,] # just keeping the first 3 records, for display purposes\n",
    "new_json = users_df.to_json(orient=\"records\")\n",
    "json.loads(new_json)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `orient=\"columns\"` works with JSON files organized as a list-of-dictionaries, where each dictionary is an entire column (the names are the row-names in the tabular data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': {'0': 1, '1': 2, '2': 3},\n",
       " 'name': {'0': 'Leanne Graham', '1': 'Ervin Howell', '2': 'Clementine Bauch'},\n",
       " 'username': {'0': 'Bret', '1': 'Antonette', '2': 'Samantha'},\n",
       " 'email': {'0': 'Sincere@april.biz',\n",
       "  '1': 'Shanna@melissa.tv',\n",
       "  '2': 'Nathan@yesenia.net'},\n",
       " 'phone': {'0': '1-770-736-8031 x56442',\n",
       "  '1': '010-692-6593 x09125',\n",
       "  '2': '1-463-123-4447'},\n",
       " 'website': {'0': 'hildegard.org', '1': 'anastasia.net', '2': 'ramiro.info'},\n",
       " 'address.street': {'0': 'Kulas Light',\n",
       "  '1': 'Victor Plains',\n",
       "  '2': 'Douglas Extension'},\n",
       " 'address.suite': {'0': 'Apt. 556', '1': 'Suite 879', '2': 'Suite 847'},\n",
       " 'address.city': {'0': 'Gwenborough',\n",
       "  '1': 'Wisokyburgh',\n",
       "  '2': 'McKenziehaven'},\n",
       " 'address.zipcode': {'0': '92998-3874', '1': '90566-7771', '2': '59590-4157'},\n",
       " 'address.geo.lat': {'0': '-37.3159', '1': '-43.9509', '2': '-68.6102'},\n",
       " 'address.geo.lng': {'0': '81.1496', '1': '-34.4618', '2': '-47.0653'},\n",
       " 'company.name': {'0': 'Romaguera-Crona',\n",
       "  '1': 'Deckow-Crist',\n",
       "  '2': 'Romaguera-Jacobson'},\n",
       " 'company.catchPhrase': {'0': 'Multi-layered client-server neural-net',\n",
       "  '1': 'Proactive didactic contingency',\n",
       "  '2': 'Face to face bifurcated interface'},\n",
       " 'company.bs': {'0': 'harness real-time e-markets',\n",
       "  '1': 'synergize scalable supply-chains',\n",
       "  '2': 'e-enable strategic applications'}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_json = users_df.to_json(orient=\"columns\")\n",
    "json.loads(new_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `orient=\"split\"` works with JSON files organized as dictionary with three lists: `columns` lists the column names, `index` lists the row names, and `data` is a list-of-lists of data points, one list for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'columns': ['id',\n",
       "  'name',\n",
       "  'username',\n",
       "  'email',\n",
       "  'phone',\n",
       "  'website',\n",
       "  'address.street',\n",
       "  'address.suite',\n",
       "  'address.city',\n",
       "  'address.zipcode',\n",
       "  'address.geo.lat',\n",
       "  'address.geo.lng',\n",
       "  'company.name',\n",
       "  'company.catchPhrase',\n",
       "  'company.bs'],\n",
       " 'index': [0, 1, 2],\n",
       " 'data': [[1,\n",
       "   'Leanne Graham',\n",
       "   'Bret',\n",
       "   'Sincere@april.biz',\n",
       "   '1-770-736-8031 x56442',\n",
       "   'hildegard.org',\n",
       "   'Kulas Light',\n",
       "   'Apt. 556',\n",
       "   'Gwenborough',\n",
       "   '92998-3874',\n",
       "   '-37.3159',\n",
       "   '81.1496',\n",
       "   'Romaguera-Crona',\n",
       "   'Multi-layered client-server neural-net',\n",
       "   'harness real-time e-markets'],\n",
       "  [2,\n",
       "   'Ervin Howell',\n",
       "   'Antonette',\n",
       "   'Shanna@melissa.tv',\n",
       "   '010-692-6593 x09125',\n",
       "   'anastasia.net',\n",
       "   'Victor Plains',\n",
       "   'Suite 879',\n",
       "   'Wisokyburgh',\n",
       "   '90566-7771',\n",
       "   '-43.9509',\n",
       "   '-34.4618',\n",
       "   'Deckow-Crist',\n",
       "   'Proactive didactic contingency',\n",
       "   'synergize scalable supply-chains'],\n",
       "  [3,\n",
       "   'Clementine Bauch',\n",
       "   'Samantha',\n",
       "   'Nathan@yesenia.net',\n",
       "   '1-463-123-4447',\n",
       "   'ramiro.info',\n",
       "   'Douglas Extension',\n",
       "   'Suite 847',\n",
       "   'McKenziehaven',\n",
       "   '59590-4157',\n",
       "   '-68.6102',\n",
       "   '-47.0653',\n",
       "   'Romaguera-Jacobson',\n",
       "   'Face to face bifurcated interface',\n",
       "   'e-enable strategic applications']]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_json = users_df.to_json(orient=\"split\")\n",
    "json.loads(new_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `orient=\"index\"` is like `orient=\"records\"` but includes the name of each row in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'id': 1,\n",
       "  'name': 'Leanne Graham',\n",
       "  'username': 'Bret',\n",
       "  'email': 'Sincere@april.biz',\n",
       "  'phone': '1-770-736-8031 x56442',\n",
       "  'website': 'hildegard.org',\n",
       "  'address.street': 'Kulas Light',\n",
       "  'address.suite': 'Apt. 556',\n",
       "  'address.city': 'Gwenborough',\n",
       "  'address.zipcode': '92998-3874',\n",
       "  'address.geo.lat': '-37.3159',\n",
       "  'address.geo.lng': '81.1496',\n",
       "  'company.name': 'Romaguera-Crona',\n",
       "  'company.catchPhrase': 'Multi-layered client-server neural-net',\n",
       "  'company.bs': 'harness real-time e-markets'},\n",
       " '1': {'id': 2,\n",
       "  'name': 'Ervin Howell',\n",
       "  'username': 'Antonette',\n",
       "  'email': 'Shanna@melissa.tv',\n",
       "  'phone': '010-692-6593 x09125',\n",
       "  'website': 'anastasia.net',\n",
       "  'address.street': 'Victor Plains',\n",
       "  'address.suite': 'Suite 879',\n",
       "  'address.city': 'Wisokyburgh',\n",
       "  'address.zipcode': '90566-7771',\n",
       "  'address.geo.lat': '-43.9509',\n",
       "  'address.geo.lng': '-34.4618',\n",
       "  'company.name': 'Deckow-Crist',\n",
       "  'company.catchPhrase': 'Proactive didactic contingency',\n",
       "  'company.bs': 'synergize scalable supply-chains'},\n",
       " '2': {'id': 3,\n",
       "  'name': 'Clementine Bauch',\n",
       "  'username': 'Samantha',\n",
       "  'email': 'Nathan@yesenia.net',\n",
       "  'phone': '1-463-123-4447',\n",
       "  'website': 'ramiro.info',\n",
       "  'address.street': 'Douglas Extension',\n",
       "  'address.suite': 'Suite 847',\n",
       "  'address.city': 'McKenziehaven',\n",
       "  'address.zipcode': '59590-4157',\n",
       "  'address.geo.lat': '-68.6102',\n",
       "  'address.geo.lng': '-47.0653',\n",
       "  'company.name': 'Romaguera-Jacobson',\n",
       "  'company.catchPhrase': 'Face to face bifurcated interface',\n",
       "  'company.bs': 'e-enable strategic applications'}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_json = users_df.to_json(orient=\"index\")\n",
    "json.loads(new_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `orient=\"values\"` only contains the datapoints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  'Leanne Graham',\n",
       "  'Bret',\n",
       "  'Sincere@april.biz',\n",
       "  '1-770-736-8031 x56442',\n",
       "  'hildegard.org',\n",
       "  'Kulas Light',\n",
       "  'Apt. 556',\n",
       "  'Gwenborough',\n",
       "  '92998-3874',\n",
       "  '-37.3159',\n",
       "  '81.1496',\n",
       "  'Romaguera-Crona',\n",
       "  'Multi-layered client-server neural-net',\n",
       "  'harness real-time e-markets'],\n",
       " [2,\n",
       "  'Ervin Howell',\n",
       "  'Antonette',\n",
       "  'Shanna@melissa.tv',\n",
       "  '010-692-6593 x09125',\n",
       "  'anastasia.net',\n",
       "  'Victor Plains',\n",
       "  'Suite 879',\n",
       "  'Wisokyburgh',\n",
       "  '90566-7771',\n",
       "  '-43.9509',\n",
       "  '-34.4618',\n",
       "  'Deckow-Crist',\n",
       "  'Proactive didactic contingency',\n",
       "  'synergize scalable supply-chains'],\n",
       " [3,\n",
       "  'Clementine Bauch',\n",
       "  'Samantha',\n",
       "  'Nathan@yesenia.net',\n",
       "  '1-463-123-4447',\n",
       "  'ramiro.info',\n",
       "  'Douglas Extension',\n",
       "  'Suite 847',\n",
       "  'McKenziehaven',\n",
       "  '59590-4157',\n",
       "  '-68.6102',\n",
       "  '-47.0653',\n",
       "  'Romaguera-Jacobson',\n",
       "  'Face to face bifurcated interface',\n",
       "  'e-enable strategic applications']]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_json = users_df.to_json(orient=\"values\")\n",
    "json.loads(new_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save these files to disk, specify a filename (using the `os.chdir()` function to change the working directory to the folder in which you save to save this file), or a filename and path, for the first parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df.to_json(\"myjson.json\", orient=\"values\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
